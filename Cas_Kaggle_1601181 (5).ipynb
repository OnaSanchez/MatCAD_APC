{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats\n",
    "\n",
    "# Funcio per a llegir dades en format csv\n",
    "def load_dataset(path):\n",
    "    dataset = pd.read_csv(path, header=0, delimiter=',')\n",
    "    return dataset\n",
    "\n",
    "# Carreguem dataset d'exemple\n",
    "dataset_advanced = load_dataset('advanced_stats.csv')\n",
    "dataset_allgames = load_dataset('allgames_stats.csv')\n",
    "dataset_allstar = load_dataset('allstar_games_stats.csv')\n",
    "dataset_gamehigh = load_dataset('game_highs_stats.csv')\n",
    "dataset_pergame = load_dataset('per_game_stats.csv')\n",
    "dataset_salaries = load_dataset('salaries.csv')\n",
    "dataset_totals = load_dataset('totals_stats.csv')\n",
    "\n",
    "data_advanced = dataset_advanced.values\n",
    "data_allgames = dataset_allgames.values\n",
    "data_allstar = dataset_allstar.values\n",
    "data_gamehigh = dataset_gamehigh.values\n",
    "data_pergame = dataset_pergame.values\n",
    "data_salaries = dataset_salaries.values\n",
    "data_totals = dataset_totals.values\n",
    "\n",
    "print(\"Dimensionalitat de la BBDD:\", dataset_advanced.shape)\n",
    "print(\"Dimensionalitat de la BBDD:\", dataset_allgames.shape)\n",
    "print(\"Dimensionalitat de la BBDD:\", dataset_allstar.shape)\n",
    "print(\"Dimensionalitat de la BBDD:\", dataset_gamehigh.shape)\n",
    "print(\"Dimensionalitat de la BBDD:\", dataset_pergame.shape)\n",
    "print(\"Dimensionalitat de la BBDD:\", dataset_salaries.shape)\n",
    "print(\"Dimensionalitat de la BBDD:\", dataset_totals.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualització de les dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_allgames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_allgames.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_allstar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_allstar.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_gamehigh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_gamehigh.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pergame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pergame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_salaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_salaries.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_totals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_totals.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_allgames.info()\n",
    "# dataset_copy2 = dataset_allgames.copy()\n",
    "# lebron = []\n",
    "# jordan = []\n",
    "# kobe = []\n",
    "# for i in dataset_copy2[\"Player\"]:\n",
    "#     if i == 'Lebron James':\n",
    "#         lebron.append(1)\n",
    "#         jordan.append(0)\n",
    "#         kobe.append(0)\n",
    "#     if i == 'Michael Jordan':\n",
    "#         lebron.append(0)\n",
    "#         jordan.append(1)\n",
    "#         kobe.append(0)\n",
    "#     if i == 'Kobe Bryant':\n",
    "#         lebron.append(0)\n",
    "#         jordan.append(0)\n",
    "#         kobe.append(1)\n",
    "# victories = []\n",
    "# for i in dataset_copy2[\"Result\"]:\n",
    "#     if i == 'W':\n",
    "#         victories.append(1)\n",
    "#     if i == 'L':\n",
    "#         victories.append(0)\n",
    "# dataset_copy2 = dataset_copy2.assign(Lebron = lebron)\n",
    "# dataset_copy2 = dataset_copy2.assign(Jordan = jordan)\n",
    "# dataset_copy2 = dataset_copy2.assign(Kobe = kobe)\n",
    "# dataset_copy2 = dataset_copy2.assign(Victories = victories)\n",
    "# print(dataset_copy2.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estudi del dataset amb el que es treballarà."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_advanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_advanced.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_copy = dataset_advanced.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creació de 3 columnes noves per indicar de quin jugador es tracta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lebron = []\n",
    "jordan = []\n",
    "kobe = []\n",
    "for i in dataset_copy[\"Player\"]:\n",
    "    if i == 'Lebron James':\n",
    "        lebron.append(1)\n",
    "        jordan.append(0)\n",
    "        kobe.append(0)\n",
    "    if i == 'Michael Jordan':\n",
    "        lebron.append(0)\n",
    "        jordan.append(1)\n",
    "        kobe.append(0)\n",
    "    if i == 'Kobe Bryant':\n",
    "        lebron.append(0)\n",
    "        jordan.append(0)\n",
    "        kobe.append(1)\n",
    "\n",
    "dataset_copy = dataset_copy.assign(Lebron = lebron)\n",
    "dataset_copy = dataset_copy.assign(Jordan = jordan)\n",
    "dataset_copy = dataset_copy.assign(Kobe = kobe)\n",
    "dataset_copy.info()\n",
    "dataset_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_copy.drop(['Player'], axis = 1)\n",
    "correlacio = dataset_copy.corr()\n",
    "correlacio[\"PER\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primers estudis de les correlacions per veure els atributs més rellevants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "objectiu = \"PER\"\n",
    "for i in range(len(correlacio[objectiu])):\n",
    "    if (correlacio[objectiu][i]) > 0.5 and correlacio[objectiu][i] != 1:\n",
    "        l.append(i)\n",
    "print(correlacio[objectiu][l])\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_corr = ['PER','TS%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'USG%', 'OWS', 'OBPM', 'DBPM', 'BPM', 'VORP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "dataset_cor = dataset_copy.copy()\n",
    "\n",
    "for i in dataset_copy:\n",
    "    if i not in names_corr:\n",
    "        dataset_cor = dataset_cor.drop(i, axis = 1)\n",
    "\n",
    "correlacio = dataset_cor.corr() \n",
    "\n",
    "plt.figure()\n",
    "\n",
    "ax = sns.heatmap(correlacio, annot=True, linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#relacio = sns.pairplot(dataset_cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estandarització de les dades e histogrames per observar si segueixen algun tipus de distribució útil per l'estudi de la regressió."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarize(X): \n",
    "    mean = X.mean(0)\n",
    "    std = X.std(0)\n",
    "    x = X - mean\n",
    "    x /= std\n",
    "    return x\n",
    "\n",
    "for i in dataset_cor:\n",
    "    X = standarize(dataset_cor[i].values)\n",
    "    plt.figure()\n",
    "    plt.title(\"Histograma de l'atribut \"+str(i))\n",
    "    plt.xlabel(\"Attribute Value\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    hist = plt.hist(X, bins=11, range=[np.min(X), np.max(X)], histtype=\"bar\", rwidth=0.8)\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separació del dataset original en 3 de diferents per tal de predir la variable objectiu PER per a cada jugador. D'aquesta manera, el jugador que obtingui un valor més elevat en la predicció serà el millor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_aux = ['PER','TS%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'USG%', 'OWS', 'OBPM', 'DBPM', 'BPM', 'VORP', 'Lebron', 'Jordan','Kobe']\n",
    "dataset_aux = dataset_copy.copy()\n",
    "\n",
    "for i in dataset_copy:\n",
    "    if i not in names_aux:\n",
    "        dataset_aux = dataset_aux.drop(i, axis = 1)\n",
    "\n",
    "data_Lebron = dataset_aux.loc[dataset_aux[\"Lebron\"]==1]\n",
    "data_Lebron.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Jordan = dataset_aux.loc[dataset_aux[\"Jordan\"]==1]\n",
    "data_Jordan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Kobe = dataset_aux.loc[dataset_aux[\"Kobe\"]==1]\n",
    "data_Kobe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estudi dels atributs de Lebron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_Lebron:\n",
    "    if i not in [\"Lebron\", \"Jordan\", \"Kobe\"]:\n",
    "        X = standarize(data_Lebron[i].values)\n",
    "        plt.figure()\n",
    "        plt.title(\"Histograma de l'atribut \"+str(i))\n",
    "        plt.xlabel(\"Attribute Value\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        hist = plt.hist(X, bins=11, range=[np.min(X), np.max(X)], histtype=\"bar\", rwidth=0.8)\n",
    "        plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estudi dels atributs de Jordan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_Jordan:\n",
    "    if i not in [\"Lebron\", \"Jordan\", \"Kobe\"]:\n",
    "        X = standarize(data_Jordan[i].values)\n",
    "        plt.figure()\n",
    "        plt.title(\"Histograma de l'atribut \"+str(i))\n",
    "        plt.xlabel(\"Attribute Value\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        hist = plt.hist(X, bins=11, range=[np.min(X), np.max(X)], histtype=\"bar\", rwidth=0.8)\n",
    "        plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estudi dels atributs de Kobe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_Kobe:\n",
    "    if i not in [\"Lebron\", \"Jordan\", \"Kobe\"]:\n",
    "        X = standarize(data_Kobe[i].values)\n",
    "        plt.figure()\n",
    "        plt.title(\"Histograma de l'atribut \"+str(i))\n",
    "        plt.xlabel(\"Attribute Value\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        hist = plt.hist(X, bins=11, range=[np.min(X), np.max(X)], histtype=\"bar\", rwidth=0.8)\n",
    "        plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pairplot per l'estudi de les distribucions i relacions entre atributs més rellevants per cada jugador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = data_Lebron.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = data_Lebron.copy()\n",
    "\n",
    "for i in data_Lebron:\n",
    "    if i not in names_corr:\n",
    "        dl = dl.drop(i, axis = 1)\n",
    "\n",
    "correlacio = dl.corr() \n",
    "\n",
    "plt.figure()\n",
    "\n",
    "ax = sns.heatmap(correlacio, annot=True, linewidths=.5)\n",
    "relacio = sns.pairplot(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj = data_Jordan.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in data_Jordan:\n",
    "    if i not in names_corr:\n",
    "        dj = dj.drop(i, axis = 1)\n",
    "\n",
    "correlacio = dj.corr() \n",
    "\n",
    "plt.figure()\n",
    "\n",
    "ax = sns.heatmap(correlacio, annot=True, linewidths=.5)\n",
    "relacio = sns.pairplot(dj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dk = data_Kobe.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in data_Kobe:\n",
    "    if i not in names_corr:\n",
    "        dk = dk.drop(i, axis = 1)\n",
    "\n",
    "correlacio = dk.corr() \n",
    "\n",
    "plt.figure()\n",
    "\n",
    "ax = sns.heatmap(correlacio, annot=True, linewidths=.5)\n",
    "relacio = sns.pairplot(dk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definició de funcions usades en l'estudi del dataset i les prediccions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def mse(y1, y2, inici):\n",
    "    # comprovem que y1 i y2 tenen la mateixa mida\n",
    "    assert(len(y1) == len(y2))\n",
    "    mse = 0\n",
    "    i = []\n",
    "    j = []\n",
    "    for aux in range(inici, inici+len(y1)):\n",
    "        i.append(aux)\n",
    "    for aux in range(0, len(y1)):\n",
    "        j.append(aux)\n",
    "    for index1, index2 in zip(i,j):\n",
    "        mse += (y1[index1] - y2[index2])**2\n",
    "    return mse / len(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def regression(x, y):\n",
    "    # Creem un objecte de regressió de sklearn\n",
    "    regr = LinearRegression()\n",
    "    # Entrenem el model per a predir y a partir de x\n",
    "    regr.fit(x, y)\n",
    "    # Retornem el model entrenat\n",
    "    return regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, y, train_ratio=0.8):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    n_train = int(np.floor(x.shape[0]*train_ratio))\n",
    "    indices_train = indices[:n_train]\n",
    "    indices_val = indices[n_train:] \n",
    "    x_train = x[indices_train, :]\n",
    "    y_train = y[indices_train]\n",
    "    x_val = x[indices_val, :]\n",
    "    y_val = y[indices_val]\n",
    "    return x_train, y_train, x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "def lasso(x, y, a = 0.1):\n",
    "\n",
    "    # Creem un objecte de regressió de sklearn\n",
    "    regr = linear_model.Lasso(alpha=a)\n",
    "\n",
    "    # Entrenem el model per a predir y a partir de x\n",
    "    regr.fit(x, y)\n",
    "\n",
    "    # Retornem el model entrenat\n",
    "    return regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "def Bayes(x, y, t = 1e-6):\n",
    "\n",
    "    # Creem un objecte de regressió de sklearn\n",
    "    regr = BayesianRidge(tol= t)\n",
    "\n",
    "    # Entrenem el model per a predir y a partir de x\n",
    "    regr.fit(x, y)\n",
    "\n",
    "    # Retornem el model entrenat\n",
    "    return regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "def ElasNet(x, y, t = 1e-6):\n",
    "\n",
    "    # Creem un objecte de regressió de sklearn\n",
    "    regr = ElasticNet(random_state=0)\n",
    "\n",
    "    # Entrenem el model per a predir y a partir de x\n",
    "    regr.fit(x, y)\n",
    "\n",
    "    # Retornem el model entrenat\n",
    "    return regr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es decideix fer, per cada jugador:\n",
    "    - Regressor Lineal (estandaritzat i no estandaritzat)\n",
    "    - Regressor Multilineal amb els 3 atributs comuns als 3 jugadors\n",
    "    - Regressor Multilineal amb búsqueda de la combinació d'atributs més rellevants repetint l'experiment 100 cops per tenir uns valors \"estables\"\n",
    "    - PCA\n",
    "    - Lasso\n",
    "    - BayesianRidge\n",
    "    - Polinomial\n",
    "    - ElasticNet\n",
    "    - Aplicació del CrossValidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedim a estudiar quin es el millor regressor possible per a predir el \"PER\" mitjançant les dades i el resultats obtinguts en el anàlisis. Fem la recta de predicció del \"PER\" amb els atributs més rellevants mencionats abans i estudiant la qualitat de la seva predicció."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "data_Lebron_no_estandaritzat = dataset_aux.loc[dataset_aux[\"Lebron\"]==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Búsqueda dels atributs més rellevants per a cada jugador que s'usaran en les prediccions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "j = []\n",
    "k = []\n",
    "s = \"PER\"\n",
    "\n",
    "correlacio_Lebron = dl.corr()\n",
    "correlacio_Jordan = dj.corr()\n",
    "correlacio_Kobe = dk.corr()\n",
    "\n",
    "for i in range(len(correlacio_Lebron[s])):\n",
    "    if abs(correlacio_Lebron[s][i]) > 0.6 and correlacio_Lebron[s][i] != 1:\n",
    "        l.append(i)\n",
    "print(correlacio_Lebron[s][l])\n",
    "print(\"-----------------------\")\n",
    "for i in range(len(correlacio_Jordan[s])):\n",
    "    if abs(correlacio_Jordan[s][i]) > 0.6 and correlacio_Jordan[s][i] != 1:\n",
    "        j.append(i)\n",
    "print(correlacio_Jordan[s][j])\n",
    "print(\"-----------------------\")\n",
    "for i in range(len(correlacio_Kobe[s])):\n",
    "    if abs(correlacio_Kobe[s][i]) > 0.6 and correlacio_Kobe[s][i] != 1:\n",
    "        k.append(i)\n",
    "print(correlacio_Kobe[s][k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observem que els atributs comuns són TS%, OBPM i BPM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estudi correlacions per cada jugador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pairplot Lebron\n",
    "names_corr = [\"TS%\", \"DRB%\", \"TRB%\", \"OBPM\", \"BPM\", \"PER\"]\n",
    "\n",
    "dl_pairplot = data_Lebron.copy()\n",
    "\n",
    "for i in data_Lebron:\n",
    "    if i not in names_corr:\n",
    "        dl_pairplot = dl_pairplot.drop(i, axis = 1)\n",
    "\n",
    "correlacio = dl_pairplot.corr() \n",
    "\n",
    "plt.figure()\n",
    "\n",
    "ax = sns.heatmap(correlacio, annot=True, linewidths=.5)\n",
    "relacio = sns.pairplot(dl_pairplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Lebron_cp = data_Lebron.copy()\n",
    "\n",
    "y = np.array(data_Lebron['PER'])\n",
    "for i in data_Lebron_cp:\n",
    "    if i not in names_corr:\n",
    "        data_Lebron_cp = data_Lebron_cp.drop(i, axis = 1)\n",
    "\n",
    "x = data_Lebron_cp.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REPRESENTACIÓ 2 A 2 EN R3\n",
    "%matplotlib notebook\n",
    "# importamos las librerias necesarias\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "M = data_Lebron_cp.to_numpy()\n",
    "M = M.transpose()\n",
    "\n",
    "l = [i for i in range(np.shape(M)[0])]\n",
    "n = names_corr\n",
    "\n",
    "z = np.array(data_Lebron['PER'])\n",
    "\n",
    "\n",
    "for i in l:\n",
    "    for j in l:\n",
    "        if j > i:\n",
    "            print(\"PER: \",n[i],\"--\", n[j])\n",
    "            # Creamos la figura\n",
    "            fig = plt.figure()\n",
    "            # Creamos el plano 3D\n",
    "            ax = fig.gca(projection='3d')\n",
    "\n",
    "            # Definimos los datos de prueba\n",
    "            x = M[i]\n",
    "            y = M[j]\n",
    "\n",
    "            # Agregamos los puntos en el plano 3D\n",
    "            ax.scatter(x, y, z, c='g', marker='o')\n",
    "\n",
    "            # Mostramos el gráfico\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REPRESENTACIÓ 3 A 3 EN R3\n",
    "# Scatter\n",
    "%matplotlib notebook\n",
    "# importamos las librerias necesarias\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "M = data_Lebron_cp.to_numpy()\n",
    "M = M.transpose()\n",
    "\n",
    "l = [[0,1,2],[1,2,3],[2,3,4],[3,4,0], [4,0,1]]\n",
    "n = names_corr\n",
    "\n",
    "a = np.array(data_Lebron['PER'])\n",
    "a = a/max(a)\n",
    "v = [i for i in range(len(a))]\n",
    "\n",
    "for i in l:\n",
    "    print(\"PER: \",n[i[0]],\"--\", n[i[1]], \"--\", n[i[2]])\n",
    "    # Creamos la figura\n",
    "    fig = plt.figure()\n",
    "    # Creamos el plano 3D\n",
    "    ax = fig.gca(projection='3d')\n",
    "\n",
    "    # Definimos los datos de prueba\n",
    "    x = M[i[0]]\n",
    "    y = M[i[1]]\n",
    "    z = M[i[2]]\n",
    "\n",
    "    # Agregamos los puntos en el plano 3D\n",
    "    img = ax.scatter(x, y, z, c = np.take(a, v), marker='o')\n",
    "    \n",
    "#     surface = ax.plot_surface(x,y,z, cmap = \"summer\")\n",
    "    fig.colorbar(img)\n",
    "\n",
    "    # Mostramos el gráfico\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "features = names_corr\n",
    "\n",
    "pca = PCA()\n",
    "components = pca.fit_transform(data_Lebron[features])\n",
    "labels = {\n",
    "    str(i): f\"PC {i+1} ({var:.1f}%)\"\n",
    "    for i, var in enumerate(pca.explained_variance_ratio_ * 100)\n",
    "}\n",
    "\n",
    "fig = px.scatter_matrix(\n",
    "    components,\n",
    "    labels=labels,\n",
    "    dimensions=range(4),\n",
    "    color=data_Lebron[\"PER\"]\n",
    ")\n",
    "fig.update_traces(diagonal_visible=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot Jordan\n",
    "dj_pairplot = data_Jordan.copy()\n",
    "names_corr=[\"TS%\", \"STL%\", \"OBPM\", \"BPM\", \"PER\"]\n",
    "for i in data_Jordan:\n",
    "    if i not in names_corr:\n",
    "        dj_pairplot = dj_pairplot.drop(i, axis = 1)\n",
    "\n",
    "correlacio = dj_pairplot.corr() \n",
    "\n",
    "plt.figure()\n",
    "\n",
    "ax = sns.heatmap(correlacio, annot=True, linewidths=.5)\n",
    "relacio = sns.pairplot(dj_pairplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Jordan_cp = data_Jordan.copy()\n",
    "\n",
    "y = np.array(data_Jordan['PER'])\n",
    "for i in data_Jordan_cp:\n",
    "    if i not in names_corr:\n",
    "        data_Jordan_cp = data_Jordan_cp.drop(i, axis = 1)\n",
    "\n",
    "x = data_Jordan_cp.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REPRESENTACIÓ 2 A 2 EN R3\n",
    "%matplotlib notebook\n",
    "# importamos las librerias necesarias\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "M = data_Jordan_cp.to_numpy()\n",
    "M = M.transpose()\n",
    "\n",
    "l = [i for i in range(np.shape(M)[0])]\n",
    "n = names_corr\n",
    "\n",
    "z = np.array(data_Jordan['PER'])\n",
    "\n",
    "\n",
    "for i in l:\n",
    "    for j in l:\n",
    "        if j > i:\n",
    "            print(\"PER: \",n[i],\"--\", n[j])\n",
    "            # Creamos la figura\n",
    "            fig = plt.figure()\n",
    "            # Creamos el plano 3D\n",
    "            ax = fig.gca(projection='3d')\n",
    "\n",
    "            # Definimos los datos de prueba\n",
    "            x = M[i]\n",
    "            y = M[j]\n",
    "\n",
    "            # Agregamos los puntos en el plano 3D\n",
    "            ax.scatter(x, y, z, c='g', marker='o')\n",
    "\n",
    "            # Mostramos el gráfico\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REPRESENTACIÓ 3 A 3 EN R3\n",
    "# Scatter\n",
    "%matplotlib notebook\n",
    "# importamos las librerias necesarias\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "M = data_Jordan_cp.to_numpy()\n",
    "M = M.transpose()\n",
    "\n",
    "l = [[0,1,2],[1,2,3],[2,3,4],[3,4,0], [4,0,1]]\n",
    "n = names_corr\n",
    "\n",
    "a = np.array(data_Jordan['PER'])\n",
    "a = a/max(a)\n",
    "v = [i for i in range(len(a))]\n",
    "\n",
    "for i in l:\n",
    "    print(\"PER: \",n[i[0]],\"--\", n[i[1]], \"--\", n[i[2]])\n",
    "    # Creamos la figura\n",
    "    fig = plt.figure()\n",
    "    # Creamos el plano 3D\n",
    "    ax = fig.gca(projection='3d')\n",
    "\n",
    "    # Definimos los datos de prueba\n",
    "    x = M[i[0]]\n",
    "    y = M[i[1]]\n",
    "    z = M[i[2]]\n",
    "\n",
    "    # Agregamos los puntos en el plano 3D\n",
    "    img = ax.scatter(x, y, z, c = np.take(a, v), marker='o')\n",
    "    \n",
    "#     surface = ax.plot_surface(x,y,z, cmap = \"summer\")\n",
    "    fig.colorbar(img)\n",
    "\n",
    "    # Mostramos el gráfico\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "features = names_corr\n",
    "\n",
    "pca = PCA()\n",
    "components = pca.fit_transform(data_Jordan[features])\n",
    "labels = {\n",
    "    str(i): f\"PC {i+1} ({var:.1f}%)\"\n",
    "    for i, var in enumerate(pca.explained_variance_ratio_ * 100)\n",
    "}\n",
    "\n",
    "fig = px.scatter_matrix(\n",
    "    components,\n",
    "    labels=labels,\n",
    "    dimensions=range(4),\n",
    "    color=data_Jordan[\"PER\"]\n",
    ")\n",
    "fig.update_traces(diagonal_visible=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pairplot Kobe\n",
    "dk_pairplot = data_Kobe.copy()\n",
    "names_corr=[\"TS%\", \"USG%\", \"OBPM\", \"BPM\", \"OWS\", \"VORP\", \"PER\"]\n",
    "for i in data_Kobe:\n",
    "    if i not in names_corr:\n",
    "        dk_pairplot = dk_pairplot.drop(i, axis = 1)\n",
    "\n",
    "correlacio = dk_pairplot.corr() \n",
    "\n",
    "plt.figure()\n",
    "\n",
    "ax = sns.heatmap(correlacio, annot=True, linewidths=.5)\n",
    "relacio = sns.pairplot(dk_pairplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Kobe_cp = data_Kobe.copy()\n",
    "\n",
    "y = np.array(data_Kobe['PER'])\n",
    "for i in data_Kobe_cp:\n",
    "    if i not in names_corr:\n",
    "        data_Kobe_cp = data_Kobe_cp.drop(i, axis = 1)\n",
    "\n",
    "x = data_Kobe_cp.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REPRESENTACIÓ 2 A 2 EN R3\n",
    "%matplotlib notebook\n",
    "# importamos las librerias necesarias\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "M = data_Kobe_cp.to_numpy()\n",
    "M = M.transpose()\n",
    "\n",
    "l = [i for i in range(np.shape(M)[0])]\n",
    "n = names_corr\n",
    "\n",
    "z = np.array(data_Kobe['PER'])\n",
    "\n",
    "\n",
    "for i in l:\n",
    "    for j in l:\n",
    "        if j > i:\n",
    "            print(\"PER: \",n[i],\"--\", n[j])\n",
    "            # Creamos la figura\n",
    "            fig = plt.figure()\n",
    "            # Creamos el plano 3D\n",
    "            ax = fig.gca(projection='3d')\n",
    "\n",
    "            # Definimos los datos de prueba\n",
    "            x = M[i]\n",
    "            y = M[j]\n",
    "\n",
    "            # Agregamos los puntos en el plano 3D\n",
    "            ax.scatter(x, y, z, c='g', marker='o')\n",
    "\n",
    "            # Mostramos el gráfico\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REPRESENTACIÓ 3 A 3 EN R3\n",
    "# Scatter\n",
    "%matplotlib notebook\n",
    "# importamos las librerias necesarias\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "M = data_Jordan_cp.to_numpy()\n",
    "M = M.transpose()\n",
    "\n",
    "l = [[0,1,2],[1,2,3],[2,3,4],[3,4,0], [4,0,1]]\n",
    "n = names_corr\n",
    "\n",
    "a = np.array(data_Jordan['PER'])\n",
    "a = a/max(a)\n",
    "v = [i for i in range(len(a))]\n",
    "\n",
    "for i in l:\n",
    "    print(\"PER: \",n[i[0]],\"--\", n[i[1]], \"--\", n[i[2]])\n",
    "    # Creamos la figura\n",
    "    fig = plt.figure()\n",
    "    # Creamos el plano 3D\n",
    "    ax = fig.gca(projection='3d')\n",
    "\n",
    "    # Definimos los datos de prueba\n",
    "    x = M[i[0]]\n",
    "    y = M[i[1]]\n",
    "    z = M[i[2]]\n",
    "\n",
    "    # Agregamos los puntos en el plano 3D\n",
    "    img = ax.scatter(x, y, z, c = np.take(a, v), marker='o')\n",
    "    \n",
    "#     surface = ax.plot_surface(x,y,z, cmap = \"summer\")\n",
    "    fig.colorbar(img)\n",
    "\n",
    "    # Mostramos el gráfico\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "features = names_corr\n",
    "\n",
    "pca = PCA()\n",
    "components = pca.fit_transform(data_Kobe[features])\n",
    "labels = {\n",
    "    str(i): f\"PC {i+1} ({var:.1f}%)\"\n",
    "    for i, var in enumerate(pca.explained_variance_ratio_ * 100)\n",
    "}\n",
    "\n",
    "fig = px.scatter_matrix(\n",
    "    components,\n",
    "    labels=labels,\n",
    "    dimensions=range(4),\n",
    "    color=data_Kobe[\"PER\"]\n",
    ")\n",
    "fig.update_traces(diagonal_visible=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_cor = [\"TS%\", \"OBPM\", \"BPM\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressió lineal per Lebron amb les dades no estandaritzades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#REGRESSIÓ LINEAL PER LEBRON\n",
    "y = data_Lebron_no_estandaritzat[\"PER\"]\n",
    "dic = {}\n",
    "for i in [\"TS%\", \"DRB%\", \"TRB%\", \"OBPM\", \"BPM\"]:\n",
    "    if i not in [\"PER\", \"Lebron\", \"Jordan\", \"Kobe\"]:\n",
    "        x = np.array(data_Lebron_no_estandaritzat[i])\n",
    "        X = x.reshape(x.shape[0], 1) \n",
    "        regr = regression(X, y) \n",
    "        predicted = regr.predict(X)\n",
    "\n",
    "        # Mostrem la predicció del model entrenat en color vermell a la Figura anterior 1\n",
    "        plt.figure()\n",
    "        plt.title(i)\n",
    "        ax = plt.scatter(x, y)\n",
    "        plt.plot(X, predicted, 'r')\n",
    "\n",
    "        # Mostrem l'error (MSE i R2)\n",
    "        MSE = mse(y, predicted, 0)\n",
    "        r2 = r2_score(y, predicted)\n",
    "        \n",
    "        #Mirem quina és la mitja del Player Efficiency Rating\n",
    "        media = 0\n",
    "        for prediction in predicted:\n",
    "            media += prediction\n",
    "        media /= len(predicted)\n",
    "        \n",
    "        print(i)\n",
    "        print(media)\n",
    "        print(\"Mean squeared error: \", MSE)\n",
    "        print(\"R2 score: \", r2)\n",
    "        print(\"----------------------------------------------------\")\n",
    "        dic[i] = (media, MSE, r2, i)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][2] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][2]\n",
    "    if dic[clave][1] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][1]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][2], \" i valor PER de \", dic[clave_r2][0])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][1], \" i valor PER de \", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressió lineal per Lebron amb les dades estandaritzades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PER LEBRON\n",
    "y = np.array(dl[\"PER\"])\n",
    "dic = {}\n",
    "for j in [\"TS%\", \"DRB%\", \"TRB%\", \"OBPM\", \"BPM\"]:\n",
    "    x = np.array(dl[j])\n",
    "    x = x.reshape(x.shape[0], 1) \n",
    "\n",
    "    x_train, y_train, x_val, y_val = split_data(x, y)\n",
    "\n",
    "    x_t = x_train # seleccionem atribut i en conjunt de train\n",
    "    x_v = x_val # seleccionem atribut i en conjunt de val.\n",
    "    x_t = np.reshape(x_t,(x_t.shape[0],1))\n",
    "    x_v = np.reshape(x_v,(x_v.shape[0],1))\n",
    "\n",
    "    regr = regression(x_t, y_train)    \n",
    "    error = mse(y_val, regr.predict(x_v),0) # calculem error\n",
    "    r2 = r2_score(y_val, regr.predict(x_v))\n",
    "    predicted = regr.predict(x_v)\n",
    "    media = 0\n",
    "    for prediction in predicted:\n",
    "        media += prediction\n",
    "    media /= len(predicted)\n",
    "\n",
    "    print(j)\n",
    "    print(media)\n",
    "    print(\"Error en atribut %s: %f\" %(j, error))\n",
    "    print(\"R2 score en atribut %s: %f\" %(j, r2))\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "\n",
    "    dic[j] = (media, error, r2, j)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][2] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][2]\n",
    "    if dic[clave][1] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][1]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][2], \" i valor PER de \", dic[clave_r2][0])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][1], \" i valor PER de \", dic[clave_mse][0])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressió multilineal amb els 3 atributs comuns a tots els jugadors: TS%, OBPM i BPM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEBRON\n",
    "Dl_copy = data_Lebron_no_estandaritzat.copy()\n",
    "\n",
    "y = np.array(dl['PER'])\n",
    "for i in Dl_copy:\n",
    "    if i not in names_cor:\n",
    "        Dl_copy = Dl_copy.drop(i, axis = 1)\n",
    "\n",
    "x = Dl_copy.to_numpy()\n",
    "\n",
    "x_train, y_train, x_val, y_val = split_data(x, y)\n",
    "\n",
    "x_t = x_train # seleccionem atribut i en conjunt de train\n",
    "x_v = x_val # seleccionem atribut i en conjunt de val.\n",
    "# x_t = np.reshape(x_t,(x_t.shape[0],20))\n",
    "# x_v = np.reshape(x_v,(x_v.shape[0],20))\n",
    "\n",
    "regr = regression(x_t, y_train)    \n",
    "error = mse(y_val, regr.predict(x_v),0) # calculem error\n",
    "r2 = r2_score(y_val, regr.predict(x_v))\n",
    "predicted = regr.predict(x_v)\n",
    "media = 0\n",
    "for prediction in predicted:\n",
    "    media += prediction\n",
    "media /= len(predicted)\n",
    "\n",
    "print(media)\n",
    "print(\"Mean squeared error: \", error)\n",
    "print(\"R2 score: \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressió multilineal Lebron: búsqueda de la millor combinació d'atributs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "#BÚSQUEDA MILLOR COMBINACIÓ MULTILINEAL LEBRON\n",
    "\n",
    "#fem les combinacions\n",
    "names_corr_importants = [\"TS%\", \"DRB%\", \"TRB%\", \"OBPM\", \"BPM\"]\n",
    "names_combinations = []\n",
    "for i in range(2,6):\n",
    "    names_combinations+=combinations(names_corr_importants,i)\n",
    "\n",
    "#for names_cor in names_combinations:\n",
    "#    print(names_cor)\n",
    "\n",
    "#Calculem les prediccions i mirem els errors mentre creem un diccionari per cercar la combinació amb menor mse i major r2\n",
    "dic = {}\n",
    "rep = 100\n",
    "total_mitja = 0\n",
    "error = 0\n",
    "r2 = 0\n",
    "\n",
    "for names_cor in names_combinations:\n",
    "    Dl_copy = data_Lebron_no_estandaritzat.copy()\n",
    "    y = np.array(data_Lebron_no_estandaritzat['PER'])\n",
    "    for i in Dl_copy:\n",
    "        if i not in names_cor:\n",
    "            Dl_copy = Dl_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = Dl_copy.to_numpy()\n",
    "\n",
    "    for k in range(rep):\n",
    "        x_train, y_train, x_val, y_val = split_data(x, y)\n",
    "\n",
    "        x_t = x_train # seleccionem atribut i en conjunt de train\n",
    "        x_v = x_val # seleccionem atribut i en conjunt de val.\n",
    "        # x_t = np.reshape(x_t,(x_t.shape[0],20))\n",
    "        # x_v = np.reshape(x_v,(x_v.shape[0],20))\n",
    "\n",
    "        regr = regression(x_t, y_train)    \n",
    "        error += mse(y_val, regr.predict(x_v),0) # calculem error\n",
    "        r2 += r2_score(y_val, regr.predict(x_v))\n",
    "        predicted = regr.predict(x_v)\n",
    "        media = 0\n",
    "        for prediction in predicted:\n",
    "            media += prediction\n",
    "        media /= len(predicted)\n",
    "        total_mitja += media\n",
    "    \n",
    "    error /= rep\n",
    "    r2 /= rep\n",
    "    total_mitja /= rep\n",
    "    dic[names_cor] = (total_mitja, error, r2, names_cor)\n",
    "    print(names_cor)\n",
    "    print(media)\n",
    "    print(\"Mean squeared error: \", error)\n",
    "    print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][2] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][2]\n",
    "    if dic[clave][1] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][1]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][2], \" i valor PER de \", dic[clave_r2][0])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][1], \" i valor PER de \", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressió amb Lasso i búsqueda de la millor combinació d'atributs (Lebron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "#BÚSQUEDA MILLOR COMBINACIÓ LASSO LEBRON\n",
    "\n",
    "#fem les combinacions\n",
    "names_corr_importants = [\"TS%\", \"DRB%\", \"TRB%\", \"OBPM\", \"BPM\"]\n",
    "names_combinations = []\n",
    "for i in range(2,6):\n",
    "    names_combinations+=combinations(names_corr_importants,i)\n",
    "\n",
    "#for names_cor in names_combinations:\n",
    "#    print(names_cor)\n",
    "\n",
    "#Calculem les prediccions i mirem els errors mentre creem un diccionari per cercar la combinació amb menor mse i major r2\n",
    "dic = {}\n",
    "rep = 100\n",
    "total_mitja = 0\n",
    "error = 0\n",
    "r2 = 0\n",
    "\n",
    "for names_cor in names_combinations:\n",
    "    Dl_copy = data_Lebron_no_estandaritzat.copy()\n",
    "    y = np.array(data_Lebron_no_estandaritzat['PER'])\n",
    "    for i in Dl_copy:\n",
    "        if i not in names_cor:\n",
    "            Dl_copy = Dl_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = Dl_copy.to_numpy()\n",
    "\n",
    "    for k in range(rep):\n",
    "        x_train, y_train, x_val, y_val = split_data(x, y)\n",
    "\n",
    "        x_t = x_train # seleccionem atribut i en conjunt de train\n",
    "        x_v = x_val # seleccionem atribut i en conjunt de val.\n",
    "        # x_t = np.reshape(x_t,(x_t.shape[0],20))\n",
    "        # x_v = np.reshape(x_v,(x_v.shape[0],20))\n",
    "\n",
    "        regr = lasso(x_t, y_train)    \n",
    "        error += mse(y_val, regr.predict(x_v),0) # calculem error\n",
    "        r2 += r2_score(y_val, regr.predict(x_v))\n",
    "        predicted = regr.predict(x_v)\n",
    "        media = 0\n",
    "        for prediction in predicted:\n",
    "            media += prediction\n",
    "        media /= len(predicted)\n",
    "        total_mitja += media\n",
    "    \n",
    "    error /= rep\n",
    "    r2 /= rep\n",
    "    total_mitja /= rep\n",
    "    dic[names_cor] = (total_mitja, error, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][2] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][2]\n",
    "    if dic[clave][1] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][1]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][2], \" i valor PER de \", dic[clave_r2][0])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][1], \" i valor PER de \", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressió amb Bayes i búsqueda de la millor combinació d'atributs (Lebron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "#BÚSQUEDA MILLOR COMBINACIÓ BAYES LEBRON\n",
    "\n",
    "#fem les combinacions\n",
    "names_corr_importants = [\"TS%\", \"DRB%\", \"TRB%\", \"OBPM\", \"BPM\"]\n",
    "names_combinations = []\n",
    "for i in range(2,6):\n",
    "    names_combinations+=combinations(names_corr_importants,i)\n",
    "\n",
    "#for names_cor in names_combinations:\n",
    "#    print(names_cor)\n",
    "\n",
    "#Calculem les prediccions i mirem els errors mentre creem un diccionari per cercar la combinació amb menor mse i major r2\n",
    "dic = {}\n",
    "rep = 100\n",
    "total_mitja = 0\n",
    "error = 0\n",
    "r2 = 0\n",
    "\n",
    "for names_cor in names_combinations:\n",
    "    Dl_copy = data_Lebron_no_estandaritzat.copy()\n",
    "    y = np.array(data_Lebron_no_estandaritzat['PER'])\n",
    "    for i in Dl_copy:\n",
    "        if i not in names_cor:\n",
    "            Dl_copy = Dl_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = Dl_copy.to_numpy()\n",
    "\n",
    "    for k in range(rep):\n",
    "        x_train, y_train, x_val, y_val = split_data(x, y)\n",
    "\n",
    "        x_t = x_train # seleccionem atribut i en conjunt de train\n",
    "        x_v = x_val # seleccionem atribut i en conjunt de val.\n",
    "        # x_t = np.reshape(x_t,(x_t.shape[0],20))\n",
    "        # x_v = np.reshape(x_v,(x_v.shape[0],20))\n",
    "\n",
    "        regr = Bayes(x_t, y_train)    \n",
    "        error += mse(y_val, regr.predict(x_v),0) # calculem error\n",
    "        r2 += r2_score(y_val, regr.predict(x_v))\n",
    "        predicted = regr.predict(x_v)\n",
    "        media = 0\n",
    "        for prediction in predicted:\n",
    "            media += prediction\n",
    "        media /= len(predicted)\n",
    "        total_mitja += media\n",
    "    \n",
    "    error /= rep\n",
    "    r2 /= rep\n",
    "    total_mitja /= rep\n",
    "    dic[names_cor] = (total_mitja, error, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][2] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][2]\n",
    "    if dic[clave][1] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][1]\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][2], \" i valor PER de \", dic[clave_r2][0])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][1], \" i valor PER de \", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressió amb ElasNet i búsqueda de la millor combinació d'atributs (Lebron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "#BÚSQUEDA MILLOR COMBINACIÓ BAYES LEBRON\n",
    "\n",
    "#fem les combinacions\n",
    "names_corr_importants = [\"TS%\", \"DRB%\", \"TRB%\", \"OBPM\", \"BPM\"]\n",
    "names_combinations = []\n",
    "for i in range(2,6):\n",
    "    names_combinations+=combinations(names_corr_importants,i)\n",
    "\n",
    "#for names_cor in names_combinations:\n",
    "#    print(names_cor)\n",
    "\n",
    "#Calculem les prediccions i mirem els errors mentre creem un diccionari per cercar la combinació amb menor mse i major r2\n",
    "dic = {}\n",
    "rep = 100\n",
    "total_mitja = 0\n",
    "error = 0\n",
    "r2 = 0\n",
    "\n",
    "for names_cor in names_combinations:\n",
    "    Dl_copy = data_Lebron_no_estandaritzat.copy()\n",
    "    y = np.array(data_Lebron_no_estandaritzat['PER'])\n",
    "    for i in Dl_copy:\n",
    "        if i not in names_cor:\n",
    "            Dl_copy = Dl_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = Dl_copy.to_numpy()\n",
    "\n",
    "    for k in range(rep):\n",
    "        x_train, y_train, x_val, y_val = split_data(x, y)\n",
    "\n",
    "        x_t = x_train # seleccionem atribut i en conjunt de train\n",
    "        x_v = x_val # seleccionem atribut i en conjunt de val.\n",
    "        # x_t = np.reshape(x_t,(x_t.shape[0],20))\n",
    "        # x_v = np.reshape(x_v,(x_v.shape[0],20))\n",
    "\n",
    "        regr = ElasNet(x_t, y_train)    \n",
    "        error += mse(y_val, regr.predict(x_v),0) # calculem error\n",
    "        r2 += r2_score(y_val, regr.predict(x_v))\n",
    "        predicted = regr.predict(x_v)\n",
    "        media = 0\n",
    "        for prediction in predicted:\n",
    "            media += prediction\n",
    "        media /= len(predicted)\n",
    "        total_mitja += media\n",
    "    \n",
    "    error /= rep\n",
    "    r2 /= rep\n",
    "    total_mitja /= rep\n",
    "    dic[names_cor] = (total_mitja, error, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][2] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][2]\n",
    "    if dic[clave][1] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][1]\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][2], \" i valor PER de \", dic[clave_r2][0])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][1], \" i valor PER de \", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressió polinomial amb búsqueda del millor atribut i millor grau (Lebron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dl_copy = data_Lebron_no_estandaritzat.copy()\n",
    "y = Dl_copy[\"PER\"]\n",
    "\n",
    "dic = {}\n",
    "for i in [\"TS%\", \"DRB%\", \"TRB%\", \"OBPM\", \"BPM\"]:\n",
    "    x = np.array(Dl_copy[i])\n",
    "    X = x.reshape(x.shape[0], 1) \n",
    "\n",
    "    for grau in range (2,5):\n",
    "        poly = PolynomialFeatures(degree=grau, include_bias=False)\n",
    "        poly_features = poly.fit_transform(x.reshape(-1, 1))\n",
    "        poly_reg_model = LinearRegression()\n",
    "        poly_reg_model.fit(poly_features, y)\n",
    "        predicted = poly_reg_model.predict(poly_features)\n",
    "\n",
    "        # Mostrem la predicció del model entrenat en color vermell a la Figura anterior 1\n",
    "        #plt.figure()\n",
    "        #plt.title(i)\n",
    "        #ax = plt.scatter(x, y)\n",
    "        #plt.plot(X, predicted, 'r')\n",
    "\n",
    "        # Mostrem l'error (MSE i R2)\n",
    "        MSE = mse(y, predicted, 0)\n",
    "        r2 = r2_score(y, predicted)\n",
    "\n",
    "        #Mirem quina és la mitja del Player Efficiency Rating\n",
    "        media = 0\n",
    "        for prediction in predicted:\n",
    "            media += prediction\n",
    "        media /= len(predicted)\n",
    "\n",
    "        print(i, \" amb \", grau)\n",
    "        print(media)\n",
    "        print(\"Mean squeared error: \", MSE)\n",
    "        print(\"R2 score: \", r2)\n",
    "        print(\"----------------------------------------------------\")\n",
    "        \n",
    "        dic[i, \" grau: \", grau] = (media, MSE, r2, i, grau)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][2] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][2]\n",
    "    if dic[clave][1] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][1]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][2], \" i valor PER de \", dic[clave_r2][0])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][1], \" i valor PER de \", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crossvalidation Lineal (Lebron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, y, train_ratio=0.7):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    n_train = int(np.floor(x.shape[0]*train_ratio))\n",
    "    indices_train = indices[:n_train]\n",
    "    indices_val = indices[n_train:] \n",
    "    x_train = x[indices_train, :]\n",
    "    y_train = y[indices_train]\n",
    "    x_val = x[indices_val, :]\n",
    "    y_val = y[indices_val]\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "\n",
    "names_corr_importants = [\"TS%\", \"DRB%\", \"TRB%\", \"OBPM\", \"BPM\"]\n",
    "dic = {}\n",
    "for names_cor in names_corr_importants:\n",
    "    Dl_copy = data_Lebron_no_estandaritzat.copy()\n",
    "    y = np.array(Dl_copy['PER'])\n",
    "    for i in Dl_copy:\n",
    "        if i not in names_cor:\n",
    "            Dl_copy = Dl_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = Dl_copy.to_numpy()\n",
    "        \n",
    "    x_t, y_t, x_v, y_v = split_data(X, y)\n",
    "\n",
    "    regr = regression(X, y) \n",
    "    #regr = lasso(x_t, y_t, a = 0.001) \n",
    "    #regr = Bayes(X, y, t = 1e-12) \n",
    "    predicted = regr.predict(x_t)\n",
    "\n",
    "    # Mostrem la predicció del model entrenat en color vermell a la Figura anterior 1\n",
    "    fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "\n",
    "    aux = []\n",
    "    for i,j in zip(x_t,predicted):\n",
    "        aux.append(np.array([i[0],j]))\n",
    "    aux = np.array(aux)\n",
    "    aux = aux[aux[:,0].argsort()]\n",
    "\n",
    "    xi = []\n",
    "    yi = []\n",
    "\n",
    "    for i in aux:\n",
    "        xi.append(np.array([i[0]]))\n",
    "\n",
    "    pred = regr.predict(xi)\n",
    "\n",
    "    xi = []\n",
    "    for i in aux:\n",
    "        xi.append(i[0])\n",
    "        yi.append(i[1])\n",
    "\n",
    "    stdev = np.sqrt(sum((pred - y_t)**2) / (len(y_t) - 2))\n",
    "    min_pred = pred - 0.675*stdev\n",
    "    max_pred = pred + 0.675*stdev\n",
    "\n",
    "    ax.scatter(X, np.array(y), marker='o', color = \"gray\")\n",
    "    ax.plot(xi, np.array(pred), linestyle='-', label=\"OLS\")\n",
    "    ax.plot(xi, np.array(min_pred), linestyle='--', color='red', label=\"95% CI\")\n",
    "    ax.plot(xi, np.array(max_pred), linestyle='--', color='red')\n",
    "    ax.fill_between(xi, np.array(min_pred), np.array(max_pred), alpha=0.1)\n",
    "\n",
    "    # Mostrem l'error (MSE i R2)\n",
    "    MSE = mse(list(y_v), list(regr.predict(x_v)),0)\n",
    "    r2 = r2_score(y_v, regr.predict(x_v))\n",
    "\n",
    "    print(names_cor)\n",
    "    print(\"Mean squeared error: \", MSE)\n",
    "    print(\"R2 score: \", r2)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    \n",
    "    dic[names_cor] = (MSE, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][1] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][1]\n",
    "    if dic[clave][0] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][0]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][1])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crossvalidation Lasso (Lebron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "def split_data(x, y, train_ratio=0.7):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    n_train = int(np.floor(x.shape[0]*train_ratio))\n",
    "    indices_train = indices[:n_train]\n",
    "    indices_val = indices[n_train:] \n",
    "    x_train = x[indices_train, :]\n",
    "    y_train = y[indices_train]\n",
    "    x_val = x[indices_val, :]\n",
    "    y_val = y[indices_val]\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "dic = {}\n",
    "names_corr_importants = [\"TS%\", \"DRB%\", \"TRB%\", \"OBPM\", \"BPM\"]\n",
    "names_combinations = []\n",
    "for i in range(2,6):\n",
    "    names_combinations+=combinations(names_corr_importants,i)\n",
    "\n",
    "for names_cor in names_combinations:\n",
    "    Dl_copy = data_Lebron_no_estandaritzat.copy()\n",
    "    y = np.array(data_Lebron_no_estandaritzat['PER'])\n",
    "    for i in Dl_copy:\n",
    "        if i not in names_cor:\n",
    "            Dl_copy = Dl_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = Dl_copy.to_numpy()\n",
    "        \n",
    "    x_t, y_t, x_v, y_v = split_data(X, y)\n",
    "\n",
    "    #regr = regression(X, y) \n",
    "    regr = lasso(x_t, y_t, a = 0.001) \n",
    "    #regr = Bayes(X, y, t = 1e-12) \n",
    "    predicted = regr.predict(x_t)\n",
    "    # Mostrem la predicció del model entrenat en color vermell a la Figura anterior 1\n",
    "    fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "\n",
    "    aux = []\n",
    "    for i,j in zip(x_t,predicted):\n",
    "        aux.append(np.array([i[0],j]))\n",
    "    aux = np.array(aux)\n",
    "    aux = aux[aux[:,0].argsort()]\n",
    "\n",
    "    xi = []\n",
    "    yi = []\n",
    "\n",
    "    for i in aux:\n",
    "        xi.append(np.array([i[0]]))\n",
    "\n",
    "    pred = regr.predict(xi)\n",
    "\n",
    "    xi = []\n",
    "    for i in aux:\n",
    "        xi.append(i[0])\n",
    "        yi.append(i[1])\n",
    "\n",
    "    stdev = np.sqrt(sum((pred - y_t)**2) / (len(y_t) - 2))\n",
    "    min_pred = pred - 0.675*stdev\n",
    "    max_pred = pred + 0.675*stdev\n",
    "\n",
    "    ax.scatter(X, np.array(y), marker='o', color = \"gray\")\n",
    "    ax.plot(xi, np.array(pred), linestyle='-', label=\"OLS\")\n",
    "    ax.plot(xi, np.array(min_pred), linestyle='--', color='red', label=\"95% CI\")\n",
    "    ax.plot(xi, np.array(max_pred), linestyle='--', color='red')\n",
    "    ax.fill_between(xi, np.array(min_pred), np.array(max_pred), alpha=0.1)\n",
    "   \n",
    "    # Mostrem l'error (MSE i R2)\n",
    "    MSE = mse(list(y_v), list(regr.predict(x_v)),0)\n",
    "    r2 = r2_score(y_v, regr.predict(x_v))\n",
    "\n",
    "    print(names_cor)\n",
    "    print(\"Mean squeared error: \", MSE)\n",
    "    print(\"R2 score: \", r2)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    dic[names_cor] = (MSE, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][1] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][1]\n",
    "    if dic[clave][0] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][0]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][1])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crossvalidation Bayes (Lebron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "def split_data(x, y, train_ratio=0.7):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    n_train = int(np.floor(x.shape[0]*train_ratio))\n",
    "    indices_train = indices[:n_train]\n",
    "    indices_val = indices[n_train:] \n",
    "    x_train = x[indices_train, :]\n",
    "    y_train = y[indices_train]\n",
    "    x_val = x[indices_val, :]\n",
    "    y_val = y[indices_val]\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "\n",
    "names_corr_importants = [\"TS%\", \"DRB%\", \"TRB%\", \"OBPM\", \"BPM\"]\n",
    "names_combinations = []\n",
    "for i in range(2,6):\n",
    "    names_combinations+=combinations(names_corr_importants,i)\n",
    "dic = {}\n",
    "for names_cor in names_combinations:\n",
    "    Dl_copy = data_Lebron_no_estandaritzat.copy()\n",
    "    y = np.array(data_Lebron_no_estandaritzat['PER'])\n",
    "    for i in Dl_copy:\n",
    "        if i not in names_cor:\n",
    "            Dl_copy = Dl_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = Dl_copy.to_numpy()\n",
    "        \n",
    "    x_t, y_t, x_v, y_v = split_data(X, y)\n",
    "\n",
    "    #regr = regression(X, y) \n",
    "    #regr = lasso(x_t, y_t, a = 0.001) \n",
    "    regr = Bayes(X, y, t = 1e-12) \n",
    "    predicted = regr.predict(x_t)\n",
    "\n",
    "    # Mostrem la predicció del model entrenat en color vermell a la Figura anterior 1\n",
    "    fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "\n",
    "    aux = []\n",
    "    for i,j in zip(x_t,predicted):\n",
    "        aux.append(np.array([i[0],j]))\n",
    "    aux = np.array(aux)\n",
    "    aux = aux[aux[:,0].argsort()]\n",
    "\n",
    "    xi = []\n",
    "    yi = []\n",
    "\n",
    "    for i in aux:\n",
    "        xi.append(np.array([i[0]]))\n",
    "\n",
    "    pred = regr.predict(xi)\n",
    "\n",
    "    xi = []\n",
    "    for i in aux:\n",
    "        xi.append(i[0])\n",
    "        yi.append(i[1])\n",
    "\n",
    "    stdev = np.sqrt(sum((pred - y_t)**2) / (len(y_t) - 2))\n",
    "    min_pred = pred - 0.675*stdev\n",
    "    max_pred = pred + 0.675*stdev\n",
    "\n",
    "    ax.scatter(X, np.array(y), marker='o', color = \"gray\")\n",
    "    ax.plot(xi, np.array(pred), linestyle='-', label=\"OLS\")\n",
    "    ax.plot(xi, np.array(min_pred), linestyle='--', color='red', label=\"95% CI\")\n",
    "    ax.plot(xi, np.array(max_pred), linestyle='--', color='red')\n",
    "    ax.fill_between(xi, np.array(min_pred), np.array(max_pred), alpha=0.1)\n",
    "\n",
    "    media = 0\n",
    "    for pred in predicted:\n",
    "        media += pred\n",
    "    media /= len(predicted)\n",
    "    # Mostrem l'error (MSE i R2)\n",
    "    print(media)\n",
    "    MSE = mse(list(y_v), list(regr.predict(x_v)),0)\n",
    "    r2 = r2_score(y_v, regr.predict(x_v))\n",
    "\n",
    "    print(names_cor)\n",
    "    print(\"Mean squeared error: \", MSE)\n",
    "    print(\"R2 score: \", r2)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    dic[names_cor] = (MSE, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][1] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][1]\n",
    "    if dic[clave][0] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][0]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][1])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes amb els millors paràmetres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "def split_data(x, y, train_ratio=0.7):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    n_train = int(np.floor(x.shape[0]*train_ratio))\n",
    "    indices_train = indices[:n_train]\n",
    "    indices_val = indices[n_train:] \n",
    "    x_train = x[indices_train, :]\n",
    "    y_train = y[indices_train]\n",
    "    x_val = x[indices_val, :]\n",
    "    y_val = y[indices_val]\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "\n",
    "names_corr_importants = [\"TS%\", \"DRB%\", \"TRB%\", \"OBPM\", \"BPM\"]\n",
    "names_combinations = []\n",
    "for i in range(2,6):\n",
    "    names_combinations+=combinations(names_corr_importants,i)\n",
    "dic = {}\n",
    "for names_cor in names_combinations:\n",
    "    Dl_copy = data_Lebron_no_estandaritzat.copy()\n",
    "    y = np.array(data_Lebron_no_estandaritzat['PER'])\n",
    "    for i in Dl_copy:\n",
    "        if i not in names_cor:\n",
    "            Dl_copy = Dl_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = Dl_copy.to_numpy()\n",
    "        \n",
    "    x_t, y_t, x_v, y_v = split_data(X, y)\n",
    "\n",
    "    #regr = regression(X, y) \n",
    "    #regr = lasso(x_t, y_t, a = 0.001) \n",
    "    #regr = Bayes(X, y, t = 1e-12) \n",
    "    regr = BayesianRidge(n_iter = 275, tol = 0.02, alpha_1 = 0.024, alpha_2 = 0.008, lambda_1 = 0.05, lambda_2 = 0.09)\n",
    "\n",
    "    # Entrenem el model per a predir y a partir de x\n",
    "    regr.fit(X, y)\n",
    "    predicted = regr.predict(x_t)\n",
    "\n",
    "    # Mostrem la predicció del model entrenat en color vermell a la Figura anterior 1\n",
    "    fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "\n",
    "    aux = []\n",
    "    for i,j in zip(x_t,predicted):\n",
    "        aux.append(np.array([i[0],j]))\n",
    "    aux = np.array(aux)\n",
    "    aux = aux[aux[:,0].argsort()]\n",
    "\n",
    "    xi = []\n",
    "    yi = []\n",
    "\n",
    "    for i in aux:\n",
    "        xi.append(np.array([i[0]]))\n",
    "\n",
    "    pred = regr.predict(xi)\n",
    "\n",
    "    xi = []\n",
    "    for i in aux:\n",
    "        xi.append(i[0])\n",
    "        yi.append(i[1])\n",
    "\n",
    "    stdev = np.sqrt(sum((pred - y_t)**2) / (len(y_t) - 2))\n",
    "    min_pred = pred - 0.675*stdev\n",
    "    max_pred = pred + 0.675*stdev\n",
    "\n",
    "    ax.scatter(X, np.array(y), marker='o', color = \"gray\")\n",
    "    ax.plot(xi, np.array(pred), linestyle='-', label=\"OLS\")\n",
    "    ax.plot(xi, np.array(min_pred), linestyle='--', color='red', label=\"95% CI\")\n",
    "    ax.plot(xi, np.array(max_pred), linestyle='--', color='red')\n",
    "    ax.fill_between(xi, np.array(min_pred), np.array(max_pred), alpha=0.1)\n",
    "\n",
    "    # Mostrem l'error (MSE i R2)\n",
    "    MSE = mse(list(y_v), list(regr.predict(x_v)),0)\n",
    "    r2 = r2_score(y_v, regr.predict(x_v))\n",
    "\n",
    "    print(names_cor)\n",
    "    print(\"Mean squeared error: \", MSE)\n",
    "    print(\"R2 score: \", r2)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    dic[names_cor] = (MSE, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][1] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][1]\n",
    "    if dic[clave][0] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][0]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][1])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crossvalidation Multilineal (Lebron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "def split_data(x, y, train_ratio=0.7):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    n_train = int(np.floor(x.shape[0]*train_ratio))\n",
    "    indices_train = indices[:n_train]\n",
    "    indices_val = indices[n_train:] \n",
    "    x_train = x[indices_train, :]\n",
    "    y_train = y[indices_train]\n",
    "    x_val = x[indices_val, :]\n",
    "    y_val = y[indices_val]\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "\n",
    "names_corr_importants = [\"TS%\", \"DRB%\", \"TRB%\", \"OBPM\", \"BPM\"]\n",
    "names_combinations = []\n",
    "for i in range(2,6):\n",
    "    names_combinations+=combinations(names_corr_importants,i)\n",
    "\n",
    "for names_cor in names_combinations:\n",
    "    Dl_copy = data_Lebron_no_estandaritzat.copy()\n",
    "    y = np.array(data_Lebron_no_estandaritzat['PER'])\n",
    "    for i in Dl_copy:\n",
    "        if i not in names_cor:\n",
    "            Dl_copy = Dl_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = Dl_copy.to_numpy()\n",
    "        \n",
    "    x_t, y_t, x_v, y_v = split_data(X, y)\n",
    "\n",
    "    regr = regression(X, y) \n",
    "    #regr = lasso(x_t, y_t, a = 0.001) \n",
    "    #regr = Bayes(X, y, t = 1e-12) \n",
    "    predicted = regr.predict(x_t)\n",
    "\n",
    "    # Mostrem la predicció del model entrenat en color vermell a la Figura anterior 1\n",
    "    fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "\n",
    "    aux = []\n",
    "    for i,j in zip(x_t,predicted):\n",
    "        aux.append(np.array([i[0],j]))\n",
    "    aux = np.array(aux)\n",
    "    aux = aux[aux[:,0].argsort()]\n",
    "\n",
    "    xi = []\n",
    "    yi = []\n",
    "\n",
    "    for i in aux:\n",
    "        xi.append(np.array([i[0]]))\n",
    "\n",
    "    pred = regr.predict(xi)\n",
    "\n",
    "    xi = []\n",
    "    for i in aux:\n",
    "        xi.append(i[0])\n",
    "        yi.append(i[1])\n",
    "\n",
    "    stdev = np.sqrt(sum((pred - y_t)**2) / (len(y_t) - 2))\n",
    "    min_pred = pred - 0.675*stdev\n",
    "    max_pred = pred + 0.675*stdev\n",
    "\n",
    "    ax.scatter(X, np.array(y), marker='o', color = \"gray\")\n",
    "    ax.plot(xi, np.array(pred), linestyle='-', label=\"OLS\")\n",
    "    ax.plot(xi, np.array(min_pred), linestyle='--', color='red', label=\"95% CI\")\n",
    "    ax.plot(xi, np.array(max_pred), linestyle='--', color='red')\n",
    "    ax.fill_between(xi, np.array(min_pred), np.array(max_pred), alpha=0.1)\n",
    "\n",
    "    # Mostrem l'error (MSE i R2)\n",
    "    MSE = mse(list(y_v), list(regr.predict(x_v)),0)\n",
    "    r2 = r2_score(y_v, regr.predict(x_v))\n",
    "\n",
    "    print(names_cor)\n",
    "    print(\"Mean squeared error: \", MSE)\n",
    "    print(\"R2 score: \", r2)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    dic[names_cor] = (MSE, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][1] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][1]\n",
    "    if dic[clave][0] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][0]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][1])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crossvalidation ElasNet (Lebron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "from itertools import combinations\n",
    "def split_data(x, y, train_ratio=0.7):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    n_train = int(np.floor(x.shape[0]*train_ratio))\n",
    "    indices_train = indices[:n_train]\n",
    "    indices_val = indices[n_train:] \n",
    "    x_train = x[indices_train, :]\n",
    "    y_train = y[indices_train]\n",
    "    x_val = x[indices_val, :]\n",
    "    y_val = y[indices_val]\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "\n",
    "names_corr_importants = [\"TS%\", \"DRB%\", \"TRB%\", \"OBPM\", \"BPM\"]\n",
    "names_combinations = []\n",
    "for i in range(2,6):\n",
    "    names_combinations+=combinations(names_corr_importants,i)\n",
    "dic = {}\n",
    "for names_cor in names_combinations:\n",
    "    Dl_copy = data_Lebron_no_estandaritzat.copy()\n",
    "    y = np.array(data_Lebron_no_estandaritzat['PER'])\n",
    "    for i in Dl_copy:\n",
    "        if i not in names_cor:\n",
    "            Dl_copy = Dl_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = Dl_copy.to_numpy()\n",
    "        \n",
    "    x_t, y_t, x_v, y_v = split_data(X, y)\n",
    "\n",
    "    #regr = regression(X, y) \n",
    "    #regr = lasso(x_t, y_t, a = 0.001) \n",
    "    #regr = Bayes(X, y, t = 1e-12) \n",
    "    regr = ElasNet(x_t,y_t)\n",
    "    predicted = regr.predict(x_t)\n",
    "\n",
    "    # Mostrem la predicció del model entrenat en color vermell a la Figura anterior 1\n",
    "    fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "\n",
    "    aux = []\n",
    "    for i,j in zip(x_t,predicted):\n",
    "        aux.append(np.array([i[0],j]))\n",
    "    aux = np.array(aux)\n",
    "    aux = aux[aux[:,0].argsort()]\n",
    "\n",
    "    xi = []\n",
    "    yi = []\n",
    "\n",
    "    for i in aux:\n",
    "        xi.append(np.array([i[0]]))\n",
    "\n",
    "    pred = regr.predict(xi)\n",
    "\n",
    "    xi = []\n",
    "    for i in aux:\n",
    "        xi.append(i[0])\n",
    "        yi.append(i[1])\n",
    "\n",
    "    stdev = np.sqrt(sum((pred - y_t)**2) / (len(y_t) - 2))\n",
    "    min_pred = pred - 0.675*stdev\n",
    "    max_pred = pred + 0.675*stdev\n",
    "\n",
    "    ax.scatter(X, np.array(y), marker='o', color = \"gray\")\n",
    "    ax.plot(xi, np.array(pred), linestyle='-', label=\"OLS\")\n",
    "    ax.plot(xi, np.array(min_pred), linestyle='--', color='red', label=\"95% CI\")\n",
    "    ax.plot(xi, np.array(max_pred), linestyle='--', color='red')\n",
    "    ax.fill_between(xi, np.array(min_pred), np.array(max_pred), alpha=0.1)\n",
    "\n",
    "    # Mostrem l'error (MSE i R2)\n",
    "    MSE = mse(list(y_v), list(regr.predict(x_v)),0)\n",
    "    r2 = r2_score(y_v, regr.predict(x_v))\n",
    "\n",
    "    print(names_cor)\n",
    "    print(\"Mean squeared error: \", MSE)\n",
    "    print(\"R2 score: \", r2)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    dic[names_cor] = (MSE, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][1] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][1]\n",
    "    if dic[clave][0] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][0]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][1])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lineal sense estandaritzar (Jordan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LINEAL SENSE ESTANDARITZAR PER VEURE QUIN VA MILLOR!\n",
    "from sklearn.metrics import r2_score\n",
    "data_Jordan_no_estandaritzat = dataset_aux.loc[dataset_aux[\"Jordan\"]==1]\n",
    "y = data_Jordan_no_estandaritzat[\"PER\"]\n",
    "dic = {}\n",
    "for i in [\"TS%\", \"STL%\", \"OBPM\", \"BPM\"]:\n",
    "    if i not in [\"PER\", \"Lebron\", \"Jordan\", \"Kobe\"]:\n",
    "        x = np.array(data_Jordan_no_estandaritzat[i])\n",
    "        X = x.reshape(x.shape[0], 1) \n",
    "        regr = regression(X, y) \n",
    "        predicted = regr.predict(X)\n",
    "\n",
    "        # Mostrem la predicció del model entrenat en color vermell a la Figura anterior 1\n",
    "        plt.figure()\n",
    "        plt.title(i)\n",
    "        ax = plt.scatter(x, y)\n",
    "        plt.plot(X, predicted, 'r')\n",
    "\n",
    "        # Mostrem l'error (MSE i R2)\n",
    "        MSE = mse(y, predicted, 29)\n",
    "        r2 = r2_score(y, predicted)\n",
    "        \n",
    "        #Mirem quina és la mitja del Player Efficiency Rating\n",
    "        media = 0\n",
    "        for prediction in predicted:\n",
    "            media += prediction\n",
    "        media /= len(predicted)\n",
    "        \n",
    "        print(i)\n",
    "        print(media)\n",
    "        print(\"Mean squeared error: \", MSE)\n",
    "        print(\"R2 score: \", r2)\n",
    "        print(\"----------------------------------------------------\")\n",
    "        dic[i] = (media, MSE, r2, i)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][2] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][2]\n",
    "    if dic[clave][1] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][1]\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][2], \" i valor PER de \", dic[clave_r2][0])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][1], \" i valor PER de \", dic[clave_mse][0])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lineal estandaritzat (Jordan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(dj[\"PER\"])\n",
    "dic = {}\n",
    "for j in [\"TS%\", \"STL%\", \"OBPM\", \"BPM\"]:\n",
    "    if j not in [\"PER\", \"Lebron\", \"Jordan\", \"Kobe\"]:\n",
    "        x = np.array(dj[j])\n",
    "        x = x.reshape(x.shape[0], 1) \n",
    "\n",
    "        x_train, y_train, x_val, y_val = split_data(x, y)\n",
    "\n",
    "        x_t = x_train # seleccionem atribut i en conjunt de train\n",
    "        x_v = x_val # seleccionem atribut i en conjunt de val.\n",
    "        x_t = np.reshape(x_t,(x_t.shape[0],1))\n",
    "        x_v = np.reshape(x_v,(x_v.shape[0],1))\n",
    "\n",
    "        regr = regression(x_t, y_train)\n",
    "        error = mse(y_val, regr.predict(x_v),0) # calculem error\n",
    "        r2 = r2_score(y_val, regr.predict(x_v))\n",
    "        predicted = regr.predict(x_v)\n",
    "        media = 0\n",
    "        for prediction in predicted:\n",
    "            media += prediction\n",
    "        media /= len(predicted)\n",
    "        \n",
    "        print(j)\n",
    "        print(media)\n",
    "        print(\"Error en atribut %s: %f\" %(j, error))\n",
    "        print(\"R2 score en atribut %s: %f\" %(j, r2))\n",
    "        print(\"----------------------------------------------------------------\")\n",
    "        dic[j] = (media, MSE, r2, j)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][2] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][2]\n",
    "    if dic[clave][1] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][1]\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][2], \" i valor PER de \", dic[clave_r2][0])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][1], \" i valor PER de \", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multilineal amb els 3 atributs comuns: TS%, OBPM i BPM (Jordan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JORDAN\n",
    "Dj_copy = data_Jordan_no_estandaritzat.copy()\n",
    "\n",
    "y = np.array(data_Jordan_no_estandaritzat['PER'])\n",
    "for i in Dj_copy:\n",
    "    if i not in names_cor:\n",
    "        Dj_copy = Dj_copy.drop(i, axis = 1)\n",
    "\n",
    "x = Dj_copy.to_numpy()\n",
    "\n",
    "x_train, y_train, x_val, y_val = split_data(x, y)\n",
    "\n",
    "x_t = x_train # seleccionem atribut i en conjunt de train\n",
    "x_v = x_val # seleccionem atribut i en conjunt de val.\n",
    "# x_t = np.reshape(x_t,(x_t.shape[0],20))\n",
    "# x_v = np.reshape(x_v,(x_v.shape[0],20))\n",
    "\n",
    "regr = regression(x_t, y_train)    \n",
    "error = mse(y_val, regr.predict(x_v),0) # calculem error\n",
    "r2 = r2_score(y_val, regr.predict(x_v))\n",
    "predicted = regr.predict(x_v)\n",
    "media = 0\n",
    "for prediction in predicted:\n",
    "    media += prediction\n",
    "media /= len(predicted)\n",
    "\n",
    "print(media)\n",
    "print(\"Mean squeared error: \", error)\n",
    "print(\"R2 score: \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Millor combinació multilinial dels atributs més rellevants (Jordan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "#BÚSQUEDA MILLOR COMBINACIÓ MULTILINEAL JORDAN\n",
    "\n",
    "#fem les combinacions\n",
    "names_corr_importants = [\"TS%\", \"STL%\", \"OBPM\", \"BPM\"]\n",
    "names_combinations = []\n",
    "for i in range(2,5):\n",
    "    names_combinations+=combinations(names_corr_importants,i)\n",
    "\n",
    "#for names_cor in names_combinations:\n",
    "#    print(names_cor)\n",
    "\n",
    "#Calculem les prediccions i mirem els errors mentre creem un diccionari per cercar la combinació amb menor mse i major r2\n",
    "dic = {}\n",
    "rep = 100\n",
    "total_mitja = 0\n",
    "error = 0\n",
    "r2 = 0\n",
    "\n",
    "for names_cor in names_combinations:\n",
    "    DJ_copy = data_Jordan_no_estandaritzat.copy()\n",
    "    y = np.array(data_Jordan_no_estandaritzat['PER'])\n",
    "    for i in DJ_copy:\n",
    "        if i not in names_cor:\n",
    "            DJ_copy = DJ_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = DJ_copy.to_numpy()\n",
    "\n",
    "    for k in range(rep):\n",
    "        x_train, y_train, x_val, y_val = split_data(x, y)\n",
    "\n",
    "        x_t = x_train # seleccionem atribut i en conjunt de train\n",
    "        x_v = x_val # seleccionem atribut i en conjunt de val.\n",
    "        # x_t = np.reshape(x_t,(x_t.shape[0],20))\n",
    "        # x_v = np.reshape(x_v,(x_v.shape[0],20))\n",
    "\n",
    "        regr = regression(x_t, y_train)    \n",
    "        error += mse(y_val, regr.predict(x_v),0) # calculem error\n",
    "        r2 += r2_score(y_val, regr.predict(x_v))\n",
    "        predicted = regr.predict(x_v)\n",
    "        media = 0\n",
    "        for prediction in predicted:\n",
    "            media += prediction\n",
    "        media /= len(predicted)\n",
    "        total_mitja += media\n",
    "    \n",
    "    error /= rep\n",
    "    r2 /= rep\n",
    "    total_mitja /= rep\n",
    "    dic[names_cor] = (total_mitja, error, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][2] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][2]\n",
    "    if dic[clave][1] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][1]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][2], \" i valor PER de \", dic[clave_r2][0])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][1], \" i valor PER de \", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Millor combinació Lasso (Jordan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "#BÚSQUEDA MILLOR COMBINACIÓ LASSO JORDAN\n",
    "\n",
    "#fem les combinacions\n",
    "names_corr_importants = [\"TS%\", \"STL%\", \"OBPM\", \"BPM\"]\n",
    "names_combinations = []\n",
    "for i in range(2,5):\n",
    "    names_combinations+=combinations(names_corr_importants,i)\n",
    "\n",
    "#for names_cor in names_combinations:\n",
    "#    print(names_cor)\n",
    "\n",
    "#Calculem les prediccions i mirem els errors mentre creem un diccionari per cercar la combinació amb menor mse i major r2\n",
    "dic = {}\n",
    "rep = 100\n",
    "total_mitja = 0\n",
    "error = 0\n",
    "r2 = 0\n",
    "\n",
    "for names_cor in names_combinations:\n",
    "    DJ_copy = data_Jordan_no_estandaritzat.copy()\n",
    "    y = np.array(data_Jordan_no_estandaritzat['PER'])\n",
    "    for i in DJ_copy:\n",
    "        if i not in names_cor:\n",
    "            DJ_copy = DJ_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = DJ_copy.to_numpy()\n",
    "\n",
    "    for k in range(rep):\n",
    "        x_train, y_train, x_val, y_val = split_data(x, y)\n",
    "\n",
    "        x_t = x_train # seleccionem atribut i en conjunt de train\n",
    "        x_v = x_val # seleccionem atribut i en conjunt de val.\n",
    "        # x_t = np.reshape(x_t,(x_t.shape[0],20))\n",
    "        # x_v = np.reshape(x_v,(x_v.shape[0],20))\n",
    "\n",
    "        regr = lasso(x_t, y_train)    \n",
    "        error += mse(y_val, regr.predict(x_v),0) # calculem error\n",
    "        r2 += r2_score(y_val, regr.predict(x_v))\n",
    "        predicted = regr.predict(x_v)\n",
    "        media = 0\n",
    "        for prediction in predicted:\n",
    "            media += prediction\n",
    "        media /= len(predicted)\n",
    "        total_mitja += media\n",
    "    \n",
    "    error /= rep\n",
    "    r2 /= rep\n",
    "    total_mitja /= rep\n",
    "    dic[names_cor] = (total_mitja, error, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][2] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][2]\n",
    "    if dic[clave][1] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][1]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][2], \" i valor PER de \", dic[clave_r2][0])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][1], \" i valor PER de \", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Millor combinació Bayes (Jordan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "#BÚSQUEDA MILLOR COMBINACIÓ LASSO JORDAN\n",
    "\n",
    "#fem les combinacions\n",
    "names_corr_importants = [\"TS%\", \"STL%\", \"OBPM\", \"BPM\"]\n",
    "names_combinations = []\n",
    "for i in range(2,5):\n",
    "    names_combinations+=combinations(names_corr_importants,i)\n",
    "\n",
    "#for names_cor in names_combinations:\n",
    "#    print(names_cor)\n",
    "\n",
    "#Calculem les prediccions i mirem els errors mentre creem un diccionari per cercar la combinació amb menor mse i major r2\n",
    "dic = {}\n",
    "rep = 100\n",
    "total_mitja = 0\n",
    "error = 0\n",
    "r2 = 0\n",
    "\n",
    "for names_cor in names_combinations:\n",
    "    DJ_copy = data_Jordan_no_estandaritzat.copy()\n",
    "    y = np.array(data_Jordan_no_estandaritzat['PER'])\n",
    "    for i in DJ_copy:\n",
    "        if i not in names_cor:\n",
    "            DJ_copy = DJ_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = DJ_copy.to_numpy()\n",
    "\n",
    "    for k in range(rep):\n",
    "        x_train, y_train, x_val, y_val = split_data(x, y)\n",
    "\n",
    "        x_t = x_train # seleccionem atribut i en conjunt de train\n",
    "        x_v = x_val # seleccionem atribut i en conjunt de val.\n",
    "        # x_t = np.reshape(x_t,(x_t.shape[0],20))\n",
    "        # x_v = np.reshape(x_v,(x_v.shape[0],20))\n",
    "\n",
    "        regr = Bayes(x_t, y_train)    \n",
    "        error += mse(y_val, regr.predict(x_v),0) # calculem error\n",
    "        r2 += r2_score(y_val, regr.predict(x_v))\n",
    "        predicted = regr.predict(x_v)\n",
    "        media = 0\n",
    "        for prediction in predicted:\n",
    "            media += prediction\n",
    "        media /= len(predicted)\n",
    "        total_mitja += media\n",
    "    \n",
    "    error /= rep\n",
    "    r2 /= rep\n",
    "    total_mitja /= rep\n",
    "    dic[names_cor] = (total_mitja, error, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][2] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][2]\n",
    "    if dic[clave][1] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][1]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][2], \" i valor PER de \", dic[clave_r2][0])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][1], \" i valor PER de \", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Millor combinació ElasNet (Jordan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "#BÚSQUEDA MILLOR COMBINACIÓ LASSO JORDAN\n",
    "\n",
    "#fem les combinacions\n",
    "names_corr_importants = [\"TS%\", \"STL%\", \"OBPM\", \"BPM\"]\n",
    "names_combinations = []\n",
    "for i in range(2,5):\n",
    "    names_combinations+=combinations(names_corr_importants,i)\n",
    "\n",
    "#for names_cor in names_combinations:\n",
    "#    print(names_cor)\n",
    "\n",
    "#Calculem les prediccions i mirem els errors mentre creem un diccionari per cercar la combinació amb menor mse i major r2\n",
    "dic = {}\n",
    "rep = 100\n",
    "total_mitja = 0\n",
    "error = 0\n",
    "r2 = 0\n",
    "\n",
    "for names_cor in names_combinations:\n",
    "    DJ_copy = data_Jordan_no_estandaritzat.copy()\n",
    "    y = np.array(data_Jordan_no_estandaritzat['PER'])\n",
    "    for i in DJ_copy:\n",
    "        if i not in names_cor:\n",
    "            DJ_copy = DJ_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = DJ_copy.to_numpy()\n",
    "\n",
    "    for k in range(rep):\n",
    "        x_train, y_train, x_val, y_val = split_data(x, y)\n",
    "\n",
    "        x_t = x_train # seleccionem atribut i en conjunt de train\n",
    "        x_v = x_val # seleccionem atribut i en conjunt de val.\n",
    "        # x_t = np.reshape(x_t,(x_t.shape[0],20))\n",
    "        # x_v = np.reshape(x_v,(x_v.shape[0],20))\n",
    "\n",
    "        regr = ElasNet(x_t, y_train)    \n",
    "        error += mse(y_val, regr.predict(x_v),0) # calculem error\n",
    "        r2 += r2_score(y_val, regr.predict(x_v))\n",
    "        predicted = regr.predict(x_v)\n",
    "        media = 0\n",
    "        for prediction in predicted:\n",
    "            media += prediction\n",
    "        media /= len(predicted)\n",
    "        total_mitja += media\n",
    "    \n",
    "    error /= rep\n",
    "    r2 /= rep\n",
    "    total_mitja /= rep\n",
    "    dic[names_cor] = (total_mitja, error, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][2] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][2]\n",
    "    if dic[clave][1] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][1]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][2], \" i valor PER de \", dic[clave_r2][0])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][1], \" i valor PER de \", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Millor atribut i grau per polinomial (Jordan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dj_copy = data_Jordan_no_estandaritzat.copy()\n",
    "y = Dj_copy[\"PER\"]\n",
    "dic = {}\n",
    "\n",
    "for i in [\"TS%\", \"STL%\", \"OBPM\", \"BPM\"]: \n",
    "    x = np.array(Dj_copy[i])\n",
    "    X = x.reshape(x.shape[0], 1) \n",
    "\n",
    "    for grau in range (2,5):\n",
    "        poly = PolynomialFeatures(degree=grau, include_bias=False)\n",
    "        poly_features = poly.fit_transform(x.reshape(-1, 1))\n",
    "        poly_reg_model = LinearRegression()\n",
    "        poly_reg_model.fit(poly_features, y)\n",
    "        predicted = poly_reg_model.predict(poly_features)\n",
    "\n",
    "        # Mostrem la predicció del model entrenat en color vermell a la Figura anterior 1\n",
    "        #plt.figure()\n",
    "        #plt.title(i)\n",
    "        #ax = plt.scatter(x, y)\n",
    "        #plt.plot(X, predicted, 'r')\n",
    "\n",
    "        # Mostrem l'error (MSE i R2)\n",
    "        MSE = mse(y, predicted, 29)\n",
    "        r2 = r2_score(y, predicted)\n",
    "\n",
    "        #Mirem quina és la mitja del Player Efficiency Rating\n",
    "        media = 0\n",
    "        for prediction in predicted:\n",
    "            media += prediction\n",
    "        media /= len(predicted)\n",
    "\n",
    "        print(i, \" amb \", grau)\n",
    "        print(media)\n",
    "        print(\"Mean squeared error: \", MSE)\n",
    "        print(\"R2 score: \", r2)\n",
    "        print(\"----------------------------------------------------\")\n",
    "        dic[i, \" grau: \", grau] = (media, MSE, r2, i, grau)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][2] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][2]\n",
    "    if dic[clave][1] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][1]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][2], \" i valor PER de \", dic[clave_r2][0])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][1], \" i valor PER de \", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CrossValidation regressió lineal (Jordan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, y, train_ratio=0.7):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    n_train = int(np.floor(x.shape[0]*train_ratio))\n",
    "    indices_train = indices[:n_train]\n",
    "    indices_val = indices[n_train:] \n",
    "    x_train = x[indices_train, :]\n",
    "    y_train = y[indices_train]\n",
    "    x_val = x[indices_val, :]\n",
    "    y_val = y[indices_val]\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "\n",
    "names_corr_importants = [\"TS%\", \"STL%\", \"OBPM\", \"BPM\"]\n",
    "dic = {}\n",
    "for names_cor in names_corr_importants:\n",
    "    Dj_copy = data_Jordan_no_estandaritzat.copy()\n",
    "    y = np.array(Dj_copy['PER'])\n",
    "    for i in Dj_copy:\n",
    "        if i not in names_cor:\n",
    "            Dj_copy = Dj_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = Dj_copy.to_numpy()\n",
    "        \n",
    "    x_t, y_t, x_v, y_v = split_data(X, y)\n",
    "\n",
    "    regr = regression(X, y) \n",
    "    #regr = lasso(x_t, y_t, a = 0.001) \n",
    "    #regr = Bayes(X, y, t = 1e-12) \n",
    "    predicted = regr.predict(x_t)\n",
    "\n",
    "    # Mostrem la predicció del model entrenat en color vermell a la Figura anterior 1\n",
    "    fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "\n",
    "    aux = []\n",
    "    for i,j in zip(x_t,predicted):\n",
    "        aux.append(np.array([i[0],j]))\n",
    "    aux = np.array(aux)\n",
    "    aux = aux[aux[:,0].argsort()]\n",
    "\n",
    "    xi = []\n",
    "    yi = []\n",
    "\n",
    "    for i in aux:\n",
    "        xi.append(np.array([i[0]]))\n",
    "\n",
    "    pred = regr.predict(xi)\n",
    "\n",
    "    xi = []\n",
    "    for i in aux:\n",
    "        xi.append(i[0])\n",
    "        yi.append(i[1])\n",
    "\n",
    "    stdev = np.sqrt(sum((pred - y_t)**2) / (len(y_t) - 2))\n",
    "    min_pred = pred - 0.675*stdev\n",
    "    max_pred = pred + 0.675*stdev\n",
    "\n",
    "    ax.scatter(X, np.array(y), marker='o', color = \"gray\")\n",
    "    ax.plot(xi, np.array(pred), linestyle='-', label=\"OLS\")\n",
    "    ax.plot(xi, np.array(min_pred), linestyle='--', color='red', label=\"95% CI\")\n",
    "    ax.plot(xi, np.array(max_pred), linestyle='--', color='red')\n",
    "    ax.fill_between(xi, np.array(min_pred), np.array(max_pred), alpha=0.1)\n",
    "\n",
    "    # Mostrem l'error (MSE i R2)\n",
    "    MSE = mse(list(y_v), list(regr.predict(x_v)),0)\n",
    "    r2 = r2_score(y_v, regr.predict(x_v))\n",
    "\n",
    "    print(names_cor)\n",
    "    print(\"Mean squeared error: \", MSE)\n",
    "    print(\"R2 score: \", r2)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    dic[names_cor] = (MSE, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][1] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][1]\n",
    "    if dic[clave][0] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][0]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][1])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CrossValidation Lasso (Jordan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, y, train_ratio=0.7):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    n_train = int(np.floor(x.shape[0]*train_ratio))\n",
    "    indices_train = indices[:n_train]\n",
    "    indices_val = indices[n_train:] \n",
    "    x_train = x[indices_train, :]\n",
    "    y_train = y[indices_train]\n",
    "    x_val = x[indices_val, :]\n",
    "    y_val = y[indices_val]\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "\n",
    "names_corr_importants = [\"TS%\", \"STL%\", \"OBPM\", \"BPM\"]\n",
    "names_combinations = []\n",
    "for i in range(2,6):\n",
    "    names_combinations+=combinations(names_corr_importants,i)\n",
    "dic = {}\n",
    "for names_cor in names_combinations:\n",
    "    Dj_copy = data_Jordan_no_estandaritzat.copy()\n",
    "    y = np.array(Dj_copy['PER'])\n",
    "    for i in Dj_copy:\n",
    "        if i not in names_cor:\n",
    "            Dj_copy = Dj_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = Dj_copy.to_numpy()\n",
    "        \n",
    "    x_t, y_t, x_v, y_v = split_data(X, y)\n",
    "\n",
    "    #regr = regression(X, y) \n",
    "    regr = lasso(x_t, y_t, a = 0.001) \n",
    "    #regr = Bayes(X, y, t = 1e-12) \n",
    "    predicted = regr.predict(x_t)\n",
    "\n",
    "    # Mostrem la predicció del model entrenat en color vermell a la Figura anterior 1\n",
    "    fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "\n",
    "    aux = []\n",
    "    for i,j in zip(x_t,predicted):\n",
    "        aux.append(np.array([i[0],j]))\n",
    "    aux = np.array(aux)\n",
    "    aux = aux[aux[:,0].argsort()]\n",
    "\n",
    "    xi = []\n",
    "    yi = []\n",
    "\n",
    "    for i in aux:\n",
    "        xi.append(np.array([i[0]]))\n",
    "\n",
    "    pred = regr.predict(xi)\n",
    "\n",
    "    xi = []\n",
    "    for i in aux:\n",
    "        xi.append(i[0])\n",
    "        yi.append(i[1])\n",
    "\n",
    "    stdev = np.sqrt(sum((pred - y_t)**2) / (len(y_t) - 2))\n",
    "    min_pred = pred - 0.675*stdev\n",
    "    max_pred = pred + 0.675*stdev\n",
    "\n",
    "    ax.scatter(X, np.array(y), marker='o', color = \"gray\")\n",
    "    ax.plot(xi, np.array(pred), linestyle='-', label=\"OLS\")\n",
    "    ax.plot(xi, np.array(min_pred), linestyle='--', color='red', label=\"95% CI\")\n",
    "    ax.plot(xi, np.array(max_pred), linestyle='--', color='red')\n",
    "    ax.fill_between(xi, np.array(min_pred), np.array(max_pred), alpha=0.1)\n",
    "\n",
    "    media = 0\n",
    "    for pred in predicted:\n",
    "        media += pred\n",
    "    media /= len(predicted)\n",
    "    # Mostrem l'error (MSE i R2)\n",
    "    print(media)\n",
    "    MSE = mse(list(y_v), list(regr.predict(x_v)),0)\n",
    "    r2 = r2_score(y_v, regr.predict(x_v))\n",
    "\n",
    "    print(names_cor)\n",
    "    print(\"Mean squeared error: \", MSE)\n",
    "    print(\"R2 score: \", r2)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    dic[names_cor] = (MSE, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][1] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][1]\n",
    "    if dic[clave][0] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][0]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][1])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CrossValidation amb els millors parametres pel Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, y, train_ratio=0.7):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    n_train = int(np.floor(x.shape[0]*train_ratio))\n",
    "    indices_train = indices[:n_train]\n",
    "    indices_val = indices[n_train:] \n",
    "    x_train = x[indices_train, :]\n",
    "    y_train = y[indices_train]\n",
    "    x_val = x[indices_val, :]\n",
    "    y_val = y[indices_val]\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "\n",
    "names_corr_importants = [\"TS%\", \"STL%\", \"OBPM\", \"BPM\"]\n",
    "names_combinations = []\n",
    "for i in range(2,6):\n",
    "    names_combinations+=combinations(names_corr_importants,i)\n",
    "dic = {}\n",
    "for names_cor in names_combinations:\n",
    "    Dj_copy = data_Jordan_no_estandaritzat.copy()\n",
    "    y = np.array(Dj_copy['PER'])\n",
    "    for i in Dj_copy:\n",
    "        if i not in names_cor:\n",
    "            Dj_copy = Dj_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = Dj_copy.to_numpy()\n",
    "        \n",
    "    x_t, y_t, x_v, y_v = split_data(X, y)\n",
    "\n",
    "    #regr = regression(X, y) \n",
    "    #regr = lasso(x_t, y_t, a = 0.001) \n",
    "    #regr = Bayes(X, y, t = 1e-12) \n",
    "    regr = linear_model.Lasso(alpha=1.81, selection=\"cyclic\", tol=0.00017)\n",
    "    regr.fit(x_t, y_t) \n",
    "    predicted = regr.predict(x_t)\n",
    "\n",
    "    # Mostrem la predicció del model entrenat en color vermell a la Figura anterior 1\n",
    "    fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "\n",
    "    aux = []\n",
    "    for i,j in zip(x_t,predicted):\n",
    "        aux.append(np.array([i[0],j]))\n",
    "    aux = np.array(aux)\n",
    "    aux = aux[aux[:,0].argsort()]\n",
    "\n",
    "    xi = []\n",
    "    yi = []\n",
    "\n",
    "    for i in aux:\n",
    "        xi.append(np.array([i[0]]))\n",
    "\n",
    "    pred = regr.predict(xi)\n",
    "\n",
    "    xi = []\n",
    "    for i in aux:\n",
    "        xi.append(i[0])\n",
    "        yi.append(i[1])\n",
    "\n",
    "    stdev = np.sqrt(sum((pred - y_t)**2) / (len(y_t) - 2))\n",
    "    min_pred = pred - 0.675*stdev\n",
    "    max_pred = pred + 0.675*stdev\n",
    "\n",
    "    ax.scatter(X, np.array(y), marker='o', color = \"gray\")\n",
    "    ax.plot(xi, np.array(pred), linestyle='-', label=\"OLS\")\n",
    "    ax.plot(xi, np.array(min_pred), linestyle='--', color='red', label=\"95% CI\")\n",
    "    ax.plot(xi, np.array(max_pred), linestyle='--', color='red')\n",
    "    ax.fill_between(xi, np.array(min_pred), np.array(max_pred), alpha=0.1)\n",
    "\n",
    "    # Mostrem l'error (MSE i R2)\n",
    "    MSE = mse(list(y_v), list(regr.predict(x_v)),0)\n",
    "    r2 = r2_score(y_v, regr.predict(x_v))\n",
    "\n",
    "    print(names_cor)\n",
    "    print(\"Mean squeared error: \", MSE)\n",
    "    print(\"R2 score: \", r2)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    dic[names_cor] = (MSE, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][1] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][1]\n",
    "    if dic[clave][0] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][0]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][1])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CrossValidation Bayes (Jordan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, y, train_ratio=0.7):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    n_train = int(np.floor(x.shape[0]*train_ratio))\n",
    "    indices_train = indices[:n_train]\n",
    "    indices_val = indices[n_train:] \n",
    "    x_train = x[indices_train, :]\n",
    "    y_train = y[indices_train]\n",
    "    x_val = x[indices_val, :]\n",
    "    y_val = y[indices_val]\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "\n",
    "names_corr_importants = [\"TS%\", \"STL%\", \"OBPM\", \"BPM\"]\n",
    "names_combinations = []\n",
    "for i in range(2,6):\n",
    "    names_combinations+=combinations(names_corr_importants,i)\n",
    "dic = {}\n",
    "for names_cor in names_combinations:\n",
    "    Dj_copy = data_Jordan_no_estandaritzat.copy()\n",
    "    y = np.array(data_Jordan_no_estandaritzat['PER'])\n",
    "    for i in Dj_copy:\n",
    "        if i not in names_cor:\n",
    "            Dj_copy = Dj_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = Dj_copy.to_numpy()\n",
    "        \n",
    "    x_t, y_t, x_v, y_v = split_data(X, y)\n",
    "\n",
    "    #regr = regression(X, y) \n",
    "    #regr = lasso(x_t, y_t, a = 0.001) \n",
    "    regr = Bayes(X, y, t = 1e-12) \n",
    "    predicted = regr.predict(x_t)\n",
    "\n",
    "    # Mostrem la predicció del model entrenat en color vermell a la Figura anterior 1\n",
    "    fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "\n",
    "    aux = []\n",
    "    for i,j in zip(x_t,predicted):\n",
    "        aux.append(np.array([i[0],j]))\n",
    "    aux = np.array(aux)\n",
    "    aux = aux[aux[:,0].argsort()]\n",
    "\n",
    "    xi = []\n",
    "    yi = []\n",
    "\n",
    "    for i in aux:\n",
    "        xi.append(np.array([i[0]]))\n",
    "\n",
    "    pred = regr.predict(xi)\n",
    "\n",
    "    xi = []\n",
    "    for i in aux:\n",
    "        xi.append(i[0])\n",
    "        yi.append(i[1])\n",
    "\n",
    "    stdev = np.sqrt(sum((pred - y_t)**2) / (len(y_t) - 2))\n",
    "    min_pred = pred - 0.675*stdev\n",
    "    max_pred = pred + 0.675*stdev\n",
    "\n",
    "    ax.scatter(X, np.array(y), marker='o', color = \"gray\")\n",
    "    ax.plot(xi, np.array(pred), linestyle='-', label=\"OLS\")\n",
    "    ax.plot(xi, np.array(min_pred), linestyle='--', color='red', label=\"95% CI\")\n",
    "    ax.plot(xi, np.array(max_pred), linestyle='--', color='red')\n",
    "    ax.fill_between(xi, np.array(min_pred), np.array(max_pred), alpha=0.1)\n",
    "\n",
    "    # Mostrem l'error (MSE i R2)\n",
    "    MSE = mse(list(y_v), list(regr.predict(x_v)),0)\n",
    "    r2 = r2_score(y_v, regr.predict(x_v))\n",
    "\n",
    "    print(names_cor)\n",
    "    print(\"Mean squeared error: \", MSE)\n",
    "    print(\"R2 score: \", r2)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    dic[names_cor] = (MSE, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][1] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][1]\n",
    "    if dic[clave][0] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][0]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][1])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CrossValidation multilineal (Jordan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, y, train_ratio=0.7):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    n_train = int(np.floor(x.shape[0]*train_ratio))\n",
    "    indices_train = indices[:n_train]\n",
    "    indices_val = indices[n_train:] \n",
    "    x_train = x[indices_train, :]\n",
    "    y_train = y[indices_train]\n",
    "    x_val = x[indices_val, :]\n",
    "    y_val = y[indices_val]\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "\n",
    "names_corr_importants = [\"TS%\", \"STL%\", \"OBPM\", \"BPM\"]\n",
    "names_combinations = []\n",
    "for i in range(2,6):\n",
    "    names_combinations+=combinations(names_corr_importants,i)\n",
    "dic = {}\n",
    "for names_cor in names_combinations:\n",
    "    Dj_copy = data_Jordan_no_estandaritzat.copy()\n",
    "    y = np.array(data_Jordan_no_estandaritzat['PER'])\n",
    "    for i in Dj_copy:\n",
    "        if i not in names_cor:\n",
    "            Dj_copy = Dj_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = Dj_copy.to_numpy()\n",
    "        \n",
    "    x_t, y_t, x_v, y_v = split_data(X, y)\n",
    "\n",
    "    regr = regression(X, y) \n",
    "    #regr = lasso(x_t, y_t, a = 0.001) \n",
    "    #regr = Bayes(X, y, t = 1e-12) \n",
    "    predicted = regr.predict(x_t)\n",
    "\n",
    "    # Mostrem la predicció del model entrenat en color vermell a la Figura anterior 1\n",
    "    fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "\n",
    "    aux = []\n",
    "    for i,j in zip(x_t,predicted):\n",
    "        aux.append(np.array([i[0],j]))\n",
    "    aux = np.array(aux)\n",
    "    aux = aux[aux[:,0].argsort()]\n",
    "\n",
    "    xi = []\n",
    "    yi = []\n",
    "\n",
    "    for i in aux:\n",
    "        xi.append(np.array([i[0]]))\n",
    "\n",
    "    pred = regr.predict(xi)\n",
    "\n",
    "    xi = []\n",
    "    for i in aux:\n",
    "        xi.append(i[0])\n",
    "        yi.append(i[1])\n",
    "\n",
    "    stdev = np.sqrt(sum((pred - y_t)**2) / (len(y_t) - 2))\n",
    "    min_pred = pred - 0.675*stdev\n",
    "    max_pred = pred + 0.675*stdev\n",
    "\n",
    "    ax.scatter(X, np.array(y), marker='o', color = \"gray\")\n",
    "    ax.plot(xi, np.array(pred), linestyle='-', label=\"OLS\")\n",
    "    ax.plot(xi, np.array(min_pred), linestyle='--', color='red', label=\"95% CI\")\n",
    "    ax.plot(xi, np.array(max_pred), linestyle='--', color='red')\n",
    "    ax.fill_between(xi, np.array(min_pred), np.array(max_pred), alpha=0.1)\n",
    "\n",
    "    # Mostrem l'error (MSE i R2)\n",
    "    MSE = mse(list(y_v), list(regr.predict(x_v)),0)\n",
    "    r2 = r2_score(y_v, regr.predict(x_v))\n",
    "\n",
    "    print(names_cor)\n",
    "    print(\"Mean squeared error: \", MSE)\n",
    "    print(\"R2 score: \", r2)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    dic[names_cor] = (MSE, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][1] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][1]\n",
    "    if dic[clave][0] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][0]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][1])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CrossValidation ElasNet (Jordan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, y, train_ratio=0.7):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    n_train = int(np.floor(x.shape[0]*train_ratio))\n",
    "    indices_train = indices[:n_train]\n",
    "    indices_val = indices[n_train:] \n",
    "    x_train = x[indices_train, :]\n",
    "    y_train = y[indices_train]\n",
    "    x_val = x[indices_val, :]\n",
    "    y_val = y[indices_val]\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "\n",
    "names_corr_importants = [\"TS%\", \"STL%\", \"OBPM\", \"BPM\"]\n",
    "names_combinations = []\n",
    "for i in range(2,6):\n",
    "    names_combinations+=combinations(names_corr_importants,i)\n",
    "dic = {}\n",
    "for names_cor in names_combinations:\n",
    "    Dj_copy = data_Jordan_no_estandaritzat.copy()\n",
    "    y = np.array(data_Jordan_no_estandaritzat['PER'])\n",
    "    for i in Dj_copy:\n",
    "        if i not in names_cor:\n",
    "            Dj_copy = Dj_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = Dj_copy.to_numpy()\n",
    "        \n",
    "    x_t, y_t, x_v, y_v = split_data(X, y)\n",
    "\n",
    "    #regr = regression(X, y) \n",
    "    #regr = lasso(x_t, y_t, a = 0.001) \n",
    "    #regr = Bayes(X, y, t = 1e-12) \n",
    "    regr = ElasNet(X,y)\n",
    "    predicted = regr.predict(x_t)\n",
    "\n",
    "    # Mostrem la predicció del model entrenat en color vermell a la Figura anterior 1\n",
    "    fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "\n",
    "    aux = []\n",
    "    for i,j in zip(x_t,predicted):\n",
    "        aux.append(np.array([i[0],j]))\n",
    "    aux = np.array(aux)\n",
    "    aux = aux[aux[:,0].argsort()]\n",
    "\n",
    "    xi = []\n",
    "    yi = []\n",
    "\n",
    "    for i in aux:\n",
    "        xi.append(np.array([i[0]]))\n",
    "\n",
    "    pred = regr.predict(xi)\n",
    "\n",
    "    xi = []\n",
    "    for i in aux:\n",
    "        xi.append(i[0])\n",
    "        yi.append(i[1])\n",
    "\n",
    "    stdev = np.sqrt(sum((pred - y_t)**2) / (len(y_t) - 2))\n",
    "    min_pred = pred - 0.675*stdev\n",
    "    max_pred = pred + 0.675*stdev\n",
    "\n",
    "    ax.scatter(X, np.array(y), marker='o', color = \"gray\")\n",
    "    ax.plot(xi, np.array(pred), linestyle='-', label=\"OLS\")\n",
    "    ax.plot(xi, np.array(min_pred), linestyle='--', color='red', label=\"95% CI\")\n",
    "    ax.plot(xi, np.array(max_pred), linestyle='--', color='red')\n",
    "    ax.fill_between(xi, np.array(min_pred), np.array(max_pred), alpha=0.1)\n",
    "\n",
    "    # Mostrem l'error (MSE i R2)\n",
    "    MSE = mse(list(y_v), list(regr.predict(x_v)),0)\n",
    "    r2 = r2_score(y_v, regr.predict(x_v))\n",
    "\n",
    "    print(names_cor)\n",
    "    print(\"Mean squeared error: \", MSE)\n",
    "    print(\"R2 score: \", r2)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    dic[names_cor] = (MSE, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][1] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][1]\n",
    "    if dic[clave][0] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][0]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][1])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressió lineal sense estandaritzar (Kobe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LINEAL SENSE ESTANDARITZAR PER VEURE QUIN VA MILLOR!\n",
    "from sklearn.metrics import r2_score\n",
    "dic = {}\n",
    "data_Kobe_no_estandaritzat = dataset_aux.loc[dataset_aux[\"Kobe\"]==1]\n",
    "y = data_Kobe_no_estandaritzat[\"PER\"]\n",
    "for i in [\"TS%\", \"USG%\", \"OBPM\", \"BPM\", \"OWS\", \"VORP\"]:\n",
    "    if i not in [\"PER\", \"Lebron\", \"Jordan\", \"Kobe\"]:\n",
    "        x = np.array(data_Kobe_no_estandaritzat[i])\n",
    "        X = x.reshape(x.shape[0], 1) \n",
    "        regr = regression(X, y) \n",
    "        predicted = regr.predict(X)\n",
    "\n",
    "        # Mostrem la predicció del model entrenat en color vermell a la Figura anterior 1\n",
    "        plt.figure()\n",
    "        plt.title(i)\n",
    "        ax = plt.scatter(x, y)\n",
    "        plt.plot(X, predicted, 'r')\n",
    "\n",
    "        # Mostrem l'error (MSE i R2)\n",
    "        MSE = mse(y, predicted, 57)\n",
    "        r2 = r2_score(y, predicted)\n",
    "        \n",
    "        #Mirem quina és la mitja del Player Efficiency Rating\n",
    "        media = 0\n",
    "        for prediction in predicted:\n",
    "            media += prediction\n",
    "        media /= len(predicted)\n",
    "        \n",
    "        print(i)\n",
    "        print(media)\n",
    "        print(\"Mean squeared error: \", MSE)\n",
    "        print(\"R2 score: \", r2)\n",
    "        print(\"----------------------------------------------------\")\n",
    "        dic[i] = (media, MSE, r2, i)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][2] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][2]\n",
    "    if dic[clave][1] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][1]\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][2], \" i valor PER de \", dic[clave_r2][0])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][1], \" i valor PER de \", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressió lineal estandaritzat (Kobe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PER Kobe\n",
    "y = np.array(dk[\"PER\"])\n",
    "dic = {}\n",
    "for j in [\"TS%\", \"USG%\", \"OBPM\", \"BPM\", \"OWS\", \"VORP\"]:\n",
    "    if j not in [\"PER\", \"Lebron\", \"Jordan\", \"Kobe\"]:\n",
    "        x = np.array(dk[j])\n",
    "        x = x.reshape(x.shape[0], 1) \n",
    "\n",
    "        x_train, y_train, x_val, y_val = split_data(x, y)\n",
    "\n",
    "        x_t = x_train # seleccionem atribut i en conjunt de train\n",
    "        x_v = x_val # seleccionem atribut i en conjunt de val.\n",
    "        x_t = np.reshape(x_t,(x_t.shape[0],1))\n",
    "        x_v = np.reshape(x_v,(x_v.shape[0],1))\n",
    "\n",
    "        regr = regression(x_t, y_train)    \n",
    "        error = mse(y_val, regr.predict(x_v),0) # calculem error\n",
    "        r2 = r2_score(y_val, regr.predict(x_v))\n",
    "        predicted = regr.predict(x_v)\n",
    "        media = 0\n",
    "        for prediction in predicted:\n",
    "            media += prediction\n",
    "        media /= len(predicted)\n",
    "        \n",
    "        print(j)\n",
    "        print(media)\n",
    "        print(\"Error en atribut %s: %f\" %(j, error))\n",
    "        print(\"R2 score en atribut %s: %f\" %(j, r2))\n",
    "        print(\"----------------------------------------------------------------\")\n",
    "        dic[j] = (media, MSE, r2, j)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][2] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][2]\n",
    "    if dic[clave][1] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][1]\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][2], \" i valor PER de \", dic[clave_r2][0])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][1], \" i valor PER de \", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressió multilineal amb els 3 atributs comuns TS%, OBPM i BPM (Kobe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KOBE\n",
    "Dk_copy = data_Kobe_no_estandaritzat.copy()\n",
    "\n",
    "y = np.array(data_Kobe_no_estandaritzat['PER'])\n",
    "for i in Dk_copy:\n",
    "    if i not in names_cor:\n",
    "        Dk_copy = Dk_copy.drop(i, axis = 1)\n",
    "\n",
    "x = Dk_copy.to_numpy()\n",
    "\n",
    "x_train, y_train, x_val, y_val = split_data(x, y)\n",
    "\n",
    "x_t = x_train # seleccionem atribut i en conjunt de train\n",
    "x_v = x_val # seleccionem atribut i en conjunt de val.\n",
    "# x_t = np.reshape(x_t,(x_t.shape[0],20))\n",
    "# x_v = np.reshape(x_v,(x_v.shape[0],20))\n",
    "\n",
    "regr = regression(x_t, y_train)    \n",
    "error = mse(y_val, regr.predict(x_v),0) # calculem error\n",
    "r2 = r2_score(y_val, regr.predict(x_v))\n",
    "predicted = regr.predict(x_v)\n",
    "media = 0\n",
    "for prediction in predicted:\n",
    "    media += prediction\n",
    "media /= len(predicted)\n",
    "\n",
    "print(media)\n",
    "print(\"Mean squeared error: \", error)\n",
    "print(\"R2 score: \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressió multilinial (Kobe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "#BÚSQUEDA MILLOR COMBINACIÓ MULTILINEAL KOBE\n",
    "\n",
    "#fem les combinacions\n",
    "names_corr_importants = [\"TS%\", \"USG%\", \"OBPM\", \"BPM\", \"OWS\", \"VORP\"]\n",
    "names_combinations = []\n",
    "for i in range(2,7):\n",
    "    names_combinations+=combinations(names_corr_importants,i)\n",
    "\n",
    "#for names_cor in names_combinations:\n",
    "#    print(names_cor)\n",
    "\n",
    "#Calculem les prediccions i mirem els errors mentre creem un diccionari per cercar la combinació amb menor mse i major r2\n",
    "dic = {}\n",
    "rep = 100\n",
    "total_mitja = 0\n",
    "error = 0\n",
    "r2 = 0\n",
    "\n",
    "for names_cor in names_combinations:\n",
    "    DK_copy = data_Kobe_no_estandaritzat.copy()\n",
    "    y = np.array(data_Kobe_no_estandaritzat['PER'])\n",
    "    for i in DK_copy:\n",
    "        if i not in names_cor:\n",
    "            DK_copy = DK_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = DK_copy.to_numpy()\n",
    "\n",
    "    for k in range(rep):\n",
    "        x_train, y_train, x_val, y_val = split_data(x, y)\n",
    "\n",
    "        x_t = x_train # seleccionem atribut i en conjunt de train\n",
    "        x_v = x_val # seleccionem atribut i en conjunt de val.\n",
    "        # x_t = np.reshape(x_t,(x_t.shape[0],20))\n",
    "        # x_v = np.reshape(x_v,(x_v.shape[0],20))\n",
    "\n",
    "        regr = regression(x_t, y_train)    \n",
    "        error += mse(y_val, regr.predict(x_v),0) # calculem error\n",
    "        r2 += r2_score(y_val, regr.predict(x_v))\n",
    "        predicted = regr.predict(x_v)\n",
    "        media = 0\n",
    "        for prediction in predicted:\n",
    "            media += prediction\n",
    "        media /= len(predicted)\n",
    "        total_mitja += media\n",
    "    \n",
    "    error /= rep\n",
    "    r2 /= rep\n",
    "    total_mitja /= rep\n",
    "    dic[names_cor] = (total_mitja, error, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][2] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][2]\n",
    "    if dic[clave][1] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][1]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][2], \" i valor PER de \", dic[clave_r2][0])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][1], \" i valor PER de \", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressió Lasso (Kobe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "#BÚSQUEDA MILLOR COMBINACIÓ LASSO KOBE\n",
    "\n",
    "#fem les combinacions\n",
    "names_corr_importants = [\"TS%\", \"USG%\", \"OBPM\", \"BPM\", \"OWS\", \"VORP\"]\n",
    "names_combinations = []\n",
    "for i in range(2,7):\n",
    "    names_combinations+=combinations(names_corr_importants,i)\n",
    "\n",
    "#for names_cor in names_combinations:\n",
    "#    print(names_cor)\n",
    "\n",
    "#Calculem les prediccions i mirem els errors mentre creem un diccionari per cercar la combinació amb menor mse i major r2\n",
    "dic = {}\n",
    "rep = 100\n",
    "total_mitja = 0\n",
    "error = 0\n",
    "r2 = 0\n",
    "\n",
    "for names_cor in names_combinations:\n",
    "    DK_copy = data_Kobe_no_estandaritzat.copy()\n",
    "    y = np.array(data_Kobe_no_estandaritzat['PER'])\n",
    "    for i in DK_copy:\n",
    "        if i not in names_cor:\n",
    "            DK_copy = DK_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = DK_copy.to_numpy()\n",
    "\n",
    "    for k in range(rep):\n",
    "        x_train, y_train, x_val, y_val = split_data(x, y)\n",
    "\n",
    "        x_t = x_train # seleccionem atribut i en conjunt de train\n",
    "        x_v = x_val # seleccionem atribut i en conjunt de val.\n",
    "        # x_t = np.reshape(x_t,(x_t.shape[0],20))\n",
    "        # x_v = np.reshape(x_v,(x_v.shape[0],20))\n",
    "\n",
    "        regr = lasso(x_t, y_train)    \n",
    "        error += mse(y_val, regr.predict(x_v),0) # calculem error\n",
    "        r2 += r2_score(y_val, regr.predict(x_v))\n",
    "        predicted = regr.predict(x_v)\n",
    "        media = 0\n",
    "        for prediction in predicted:\n",
    "            media += prediction\n",
    "        media /= len(predicted)\n",
    "        total_mitja += media\n",
    "    \n",
    "    error /= rep\n",
    "    r2 /= rep\n",
    "    total_mitja /= rep\n",
    "    dic[names_cor] = (total_mitja, error, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][2] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][2]\n",
    "    if dic[clave][1] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][1]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][2], \" i valor PER de \", dic[clave_r2][0])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][1], \" i valor PER de \", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressió Bayes (Kobe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "#BÚSQUEDA MILLOR COMBINACIÓ LASSO KOBE\n",
    "\n",
    "#fem les combinacions\n",
    "names_corr_importants = [\"TS%\", \"USG%\", \"OBPM\", \"BPM\", \"OWS\", \"VORP\"]\n",
    "names_combinations = []\n",
    "for i in range(2,7):\n",
    "    names_combinations+=combinations(names_corr_importants,i)\n",
    "\n",
    "#for names_cor in names_combinations:\n",
    "#    print(names_cor)\n",
    "\n",
    "#Calculem les prediccions i mirem els errors mentre creem un diccionari per cercar la combinació amb menor mse i major r2\n",
    "dic = {}\n",
    "rep = 100\n",
    "total_mitja = 0\n",
    "error = 0\n",
    "r2 = 0\n",
    "\n",
    "for names_cor in names_combinations:\n",
    "    DK_copy = data_Kobe_no_estandaritzat.copy()\n",
    "    y = np.array(data_Kobe_no_estandaritzat['PER'])\n",
    "    for i in DK_copy:\n",
    "        if i not in names_cor:\n",
    "            DK_copy = DK_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = DK_copy.to_numpy()\n",
    "\n",
    "    for k in range(rep):\n",
    "        x_train, y_train, x_val, y_val = split_data(x, y)\n",
    "\n",
    "        x_t = x_train # seleccionem atribut i en conjunt de train\n",
    "        x_v = x_val # seleccionem atribut i en conjunt de val.\n",
    "        # x_t = np.reshape(x_t,(x_t.shape[0],20))\n",
    "        # x_v = np.reshape(x_v,(x_v.shape[0],20))\n",
    "\n",
    "        regr = Bayes(x_t, y_train)    \n",
    "        error += mse(y_val, regr.predict(x_v),0) # calculem error\n",
    "        r2 += r2_score(y_val, regr.predict(x_v))\n",
    "        predicted = regr.predict(x_v)\n",
    "        media = 0\n",
    "        for prediction in predicted:\n",
    "            media += prediction\n",
    "        media /= len(predicted)\n",
    "        total_mitja += media\n",
    "    \n",
    "    error /= rep\n",
    "    r2 /= rep\n",
    "    total_mitja /= rep\n",
    "    dic[names_cor] = (total_mitja, error, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][2] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][2]\n",
    "    if dic[clave][1] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][1]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][2], \" i valor PER de \", dic[clave_r2][0])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][1], \" i valor PER de \", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressió ElasNet (Kobe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "#BÚSQUEDA MILLOR COMBINACIÓ LASSO KOBE\n",
    "\n",
    "#fem les combinacions\n",
    "names_corr_importants = [\"TS%\", \"USG%\", \"OBPM\", \"BPM\", \"OWS\", \"VORP\"]\n",
    "names_combinations = []\n",
    "for i in range(2,7):\n",
    "    names_combinations+=combinations(names_corr_importants,i)\n",
    "\n",
    "#for names_cor in names_combinations:\n",
    "#    print(names_cor)\n",
    "\n",
    "#Calculem les prediccions i mirem els errors mentre creem un diccionari per cercar la combinació amb menor mse i major r2\n",
    "dic = {}\n",
    "rep = 100\n",
    "total_mitja = 0\n",
    "error = 0\n",
    "r2 = 0\n",
    "\n",
    "for names_cor in names_combinations:\n",
    "    DK_copy = data_Kobe_no_estandaritzat.copy()\n",
    "    y = np.array(data_Kobe_no_estandaritzat['PER'])\n",
    "    for i in DK_copy:\n",
    "        if i not in names_cor:\n",
    "            DK_copy = DK_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = DK_copy.to_numpy()\n",
    "\n",
    "    for k in range(rep):\n",
    "        x_train, y_train, x_val, y_val = split_data(x, y)\n",
    "\n",
    "        x_t = x_train # seleccionem atribut i en conjunt de train\n",
    "        x_v = x_val # seleccionem atribut i en conjunt de val.\n",
    "        # x_t = np.reshape(x_t,(x_t.shape[0],20))\n",
    "        # x_v = np.reshape(x_v,(x_v.shape[0],20))\n",
    "\n",
    "        regr = ElasNet(x_t, y_train)    \n",
    "        error += mse(y_val, regr.predict(x_v),0) # calculem error\n",
    "        r2 += r2_score(y_val, regr.predict(x_v))\n",
    "        predicted = regr.predict(x_v)\n",
    "        media = 0\n",
    "        for prediction in predicted:\n",
    "            media += prediction\n",
    "        media /= len(predicted)\n",
    "        total_mitja += media\n",
    "    \n",
    "    error /= rep\n",
    "    r2 /= rep\n",
    "    total_mitja /= rep\n",
    "    dic[names_cor] = (total_mitja, error, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][2] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][2]\n",
    "    if dic[clave][1] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][1]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][2], \" i valor PER de \", dic[clave_r2][0])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][1], \" i valor PER de \", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressió polinomial (Kobe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dk_copy = data_Kobe_no_estandaritzat.copy()\n",
    "y = Dk_copy[\"PER\"]\n",
    "dic = {}\n",
    "\n",
    "for i in [\"TS%\", \"USG%\", \"OBPM\", \"BPM\", \"OWS\", \"VORP\"]: \n",
    "    x = np.array(Dk_copy[i])\n",
    "    X = x.reshape(x.shape[0], 1) \n",
    "\n",
    "    for grau in range (2,5):\n",
    "        poly = PolynomialFeatures(degree=grau, include_bias=False)\n",
    "        poly_features = poly.fit_transform(x.reshape(-1, 1))\n",
    "        poly_reg_model = LinearRegression()\n",
    "        poly_reg_model.fit(poly_features, y)\n",
    "        predicted = poly_reg_model.predict(poly_features)\n",
    "\n",
    "        # Mostrem la predicció del model entrenat en color vermell a la Figura anterior 1\n",
    "        #plt.figure()\n",
    "        #plt.title(i)\n",
    "        #ax = plt.scatter(x, y)\n",
    "        #plt.plot(X, predicted, 'r')\n",
    "\n",
    "        # Mostrem l'error (MSE i R2)\n",
    "        MSE = mse(y, predicted, 57)\n",
    "        r2 = r2_score(y, predicted)\n",
    "\n",
    "        #Mirem quina és la mitja del Player Efficiency Rating\n",
    "        media = 0\n",
    "        for prediction in predicted:\n",
    "            media += prediction\n",
    "        media /= len(predicted)\n",
    "\n",
    "        print(i, \" amb \", grau)\n",
    "        print(media)\n",
    "        print(\"Mean squeared error: \", MSE)\n",
    "        print(\"R2 score: \", r2)\n",
    "        print(\"----------------------------------------------------\")\n",
    "        dic[i, \" grau: \", grau] = (media, MSE, r2, i, grau)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][2] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][2]\n",
    "    if dic[clave][1] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][1]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][2], \" i valor PER de \", dic[clave_r2][0])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][1], \" i valor PER de \", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CrossValidation lineal (Kobe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, y, train_ratio=0.7):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    n_train = int(np.floor(x.shape[0]*train_ratio))\n",
    "    indices_train = indices[:n_train]\n",
    "    indices_val = indices[n_train:] \n",
    "    x_train = x[indices_train, :]\n",
    "    y_train = y[indices_train]\n",
    "    x_val = x[indices_val, :]\n",
    "    y_val = y[indices_val]\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "\n",
    "names_corr_importants = [\"TS%\", \"USG%\", \"OBPM\", \"BPM\", \"OWS\", \"VORP\"]\n",
    "dic = {}\n",
    "for names_cor in names_corr_importants:\n",
    "    Dk_copy = data_Kobe_no_estandaritzat.copy()\n",
    "    y = np.array(Dk_copy['PER'])\n",
    "    for i in Dk_copy:\n",
    "        if i not in names_cor:\n",
    "            Dk_copy = Dk_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = Dk_copy.to_numpy()\n",
    "        \n",
    "    x_t, y_t, x_v, y_v = split_data(X, y)\n",
    "\n",
    "    regr = regression(X, y) \n",
    "    #regr = lasso(x_t, y_t, a = 0.001) \n",
    "    #regr = Bayes(X, y, t = 1e-12) \n",
    "    predicted = regr.predict(x_t)\n",
    "\n",
    "    # Mostrem la predicció del model entrenat en color vermell a la Figura anterior 1\n",
    "    fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "\n",
    "    aux = []\n",
    "    for i,j in zip(x_t,predicted):\n",
    "        aux.append(np.array([i[0],j]))\n",
    "    aux = np.array(aux)\n",
    "    aux = aux[aux[:,0].argsort()]\n",
    "\n",
    "    xi = []\n",
    "    yi = []\n",
    "\n",
    "    for i in aux:\n",
    "        xi.append(np.array([i[0]]))\n",
    "\n",
    "    pred = regr.predict(xi)\n",
    "\n",
    "    xi = []\n",
    "    for i in aux:\n",
    "        xi.append(i[0])\n",
    "        yi.append(i[1])\n",
    "\n",
    "    stdev = np.sqrt(sum((pred - y_t)**2) / (len(y_t) - 2))\n",
    "    min_pred = pred - 0.675*stdev\n",
    "    max_pred = pred + 0.675*stdev\n",
    "\n",
    "    ax.scatter(X, np.array(y), marker='o', color = \"gray\")\n",
    "    ax.plot(xi, np.array(pred), linestyle='-', label=\"OLS\")\n",
    "    ax.plot(xi, np.array(min_pred), linestyle='--', color='red', label=\"95% CI\")\n",
    "    ax.plot(xi, np.array(max_pred), linestyle='--', color='red')\n",
    "    ax.fill_between(xi, np.array(min_pred), np.array(max_pred), alpha=0.1)\n",
    "\n",
    "    # Mostrem l'error (MSE i R2)\n",
    "    MSE = mse(list(y_v), list(regr.predict(x_v)),0)\n",
    "    r2 = r2_score(y_v, regr.predict(x_v))\n",
    "\n",
    "    print(names_cor)\n",
    "    print(\"Mean squeared error: \", MSE)\n",
    "    print(\"R2 score: \", r2)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    dic[names_cor] = (MSE, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][1] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][1]\n",
    "    if dic[clave][0] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][0]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][1])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CrossValidation Lasso (Kobe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "def split_data(x, y, train_ratio=0.7):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    n_train = int(np.floor(x.shape[0]*train_ratio))\n",
    "    indices_train = indices[:n_train]\n",
    "    indices_val = indices[n_train:] \n",
    "    x_train = x[indices_train, :]\n",
    "    y_train = y[indices_train]\n",
    "    x_val = x[indices_val, :]\n",
    "    y_val = y[indices_val]\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "\n",
    "names_corr_importants = [\"TS%\", \"USG%\", \"OBPM\", \"BPM\", \"OWS\", \"VORP\"]\n",
    "names_combinations = []\n",
    "for i in range(2,6):\n",
    "    names_combinations+=combinations(names_corr_importants,i)\n",
    "dic = {}\n",
    "for names_cor in names_combinations:\n",
    "    Dk_copy = data_Kobe_no_estandaritzat.copy()\n",
    "    y = np.array(data_Kobe_no_estandaritzat['PER'])\n",
    "    for i in Dk_copy:\n",
    "        if i not in names_cor:\n",
    "            Dk_copy = Dk_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = Dk_copy.to_numpy()\n",
    "        \n",
    "    x_t, y_t, x_v, y_v = split_data(X, y)\n",
    "\n",
    "    #regr = regression(X, y) \n",
    "    regr = lasso(x_t, y_t, a = 0.001) \n",
    "    #regr = Bayes(X, y, t = 1e-12) \n",
    "    predicted = regr.predict(x_t)\n",
    "\n",
    "    # Mostrem la predicció del model entrenat en color vermell a la Figura anterior 1\n",
    "    fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "\n",
    "    aux = []\n",
    "    for i,j in zip(x_t,predicted):\n",
    "        aux.append(np.array([i[0],j]))\n",
    "    aux = np.array(aux)\n",
    "    aux = aux[aux[:,0].argsort()]\n",
    "\n",
    "    xi = []\n",
    "    yi = []\n",
    "\n",
    "    for i in aux:\n",
    "        xi.append(np.array([i[0]]))\n",
    "\n",
    "    pred = regr.predict(xi)\n",
    "\n",
    "    xi = []\n",
    "    for i in aux:\n",
    "        xi.append(i[0])\n",
    "        yi.append(i[1])\n",
    "\n",
    "    stdev = np.sqrt(sum((pred - y_t)**2) / (len(y_t) - 2))\n",
    "    min_pred = pred - 0.675*stdev\n",
    "    max_pred = pred + 0.675*stdev\n",
    "\n",
    "    ax.scatter(X, np.array(y), marker='o', color = \"gray\")\n",
    "    ax.plot(xi, np.array(pred), linestyle='-', label=\"OLS\")\n",
    "    ax.plot(xi, np.array(min_pred), linestyle='--', color='red', label=\"95% CI\")\n",
    "    ax.plot(xi, np.array(max_pred), linestyle='--', color='red')\n",
    "    ax.fill_between(xi, np.array(min_pred), np.array(max_pred), alpha=0.1)\n",
    "\n",
    "    # Mostrem l'error (MSE i R2)\n",
    "    MSE = mse(list(y_v), list(regr.predict(x_v)),0)\n",
    "    r2 = r2_score(y_v, regr.predict(x_v))\n",
    "\n",
    "    print(names_cor)\n",
    "    print(\"Mean squeared error: \", MSE)\n",
    "    print(\"R2 score: \", r2)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    dic[names_cor] = (MSE, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][1] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][1]\n",
    "    if dic[clave][0] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][0]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][1])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CrossValidation Bayes (Kobe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "def split_data(x, y, train_ratio=0.7):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    n_train = int(np.floor(x.shape[0]*train_ratio))\n",
    "    indices_train = indices[:n_train]\n",
    "    indices_val = indices[n_train:] \n",
    "    x_train = x[indices_train, :]\n",
    "    y_train = y[indices_train]\n",
    "    x_val = x[indices_val, :]\n",
    "    y_val = y[indices_val]\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "\n",
    "names_corr_importants = [\"TS%\", \"USG%\", \"OBPM\", \"BPM\", \"OWS\", \"VORP\"]\n",
    "names_combinations = []\n",
    "for i in range(2,6):\n",
    "    names_combinations+=combinations(names_corr_importants,i)\n",
    "dic = {}\n",
    "for names_cor in names_combinations:\n",
    "    Dk_copy = data_Kobe_no_estandaritzat.copy()\n",
    "    y = np.array(data_Kobe_no_estandaritzat['PER'])\n",
    "    for i in Dk_copy:\n",
    "        if i not in names_cor:\n",
    "            Dk_copy = Dk_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = Dk_copy.to_numpy()\n",
    "        \n",
    "    x_t, y_t, x_v, y_v = split_data(X, y)\n",
    "\n",
    "    #regr = regression(X, y) \n",
    "    #regr = lasso(x_t, y_t, a = 0.001) \n",
    "    regr = Bayes(X, y, t = 1e-12) \n",
    "    predicted = regr.predict(x_t)\n",
    "\n",
    "    # Mostrem la predicció del model entrenat en color vermell a la Figura anterior 1\n",
    "    fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "\n",
    "    aux = []\n",
    "    for i,j in zip(x_t,predicted):\n",
    "        aux.append(np.array([i[0],j]))\n",
    "    aux = np.array(aux)\n",
    "    aux = aux[aux[:,0].argsort()]\n",
    "\n",
    "    xi = []\n",
    "    yi = []\n",
    "\n",
    "    for i in aux:\n",
    "        xi.append(np.array([i[0]]))\n",
    "\n",
    "    pred = regr.predict(xi)\n",
    "\n",
    "    xi = []\n",
    "    for i in aux:\n",
    "        xi.append(i[0])\n",
    "        yi.append(i[1])\n",
    "\n",
    "    stdev = np.sqrt(sum((pred - y_t)**2) / (len(y_t) - 2))\n",
    "    min_pred = pred - 0.675*stdev\n",
    "    max_pred = pred + 0.675*stdev\n",
    "\n",
    "    ax.scatter(X, np.array(y), marker='o', color = \"gray\")\n",
    "    ax.plot(xi, np.array(pred), linestyle='-', label=\"OLS\")\n",
    "    ax.plot(xi, np.array(min_pred), linestyle='--', color='red', label=\"95% CI\")\n",
    "    ax.plot(xi, np.array(max_pred), linestyle='--', color='red')\n",
    "    ax.fill_between(xi, np.array(min_pred), np.array(max_pred), alpha=0.1)\n",
    "\n",
    "    # Mostrem l'error (MSE i R2)\n",
    "    MSE = mse(list(y_v), list(regr.predict(x_v)),0)\n",
    "    r2 = r2_score(y_v, regr.predict(x_v))\n",
    "\n",
    "    print(names_cor)\n",
    "    print(\"Mean squeared error: \", MSE)\n",
    "    print(\"R2 score: \", r2)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    dic[names_cor] = (MSE, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][1] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][1]\n",
    "    if dic[clave][0] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][0]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][1])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CrossValidation multilineal (Kobe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "def split_data(x, y, train_ratio=0.7):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    n_train = int(np.floor(x.shape[0]*train_ratio))\n",
    "    indices_train = indices[:n_train]\n",
    "    indices_val = indices[n_train:] \n",
    "    x_train = x[indices_train, :]\n",
    "    y_train = y[indices_train]\n",
    "    x_val = x[indices_val, :]\n",
    "    y_val = y[indices_val]\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "\n",
    "names_corr_importants = [\"TS%\", \"USG%\", \"OBPM\", \"BPM\", \"OWS\", \"VORP\"]\n",
    "names_combinations = []\n",
    "for i in range(2,6):\n",
    "    names_combinations+=combinations(names_corr_importants,i)\n",
    "\n",
    "for names_cor in names_combinations:\n",
    "    Dk_copy = data_Kobe_no_estandaritzat.copy()\n",
    "    y = np.array(data_Kobe_no_estandaritzat['PER'])\n",
    "    for i in Dk_copy:\n",
    "        if i not in names_cor:\n",
    "            Dk_copy = Dk_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = Dk_copy.to_numpy()\n",
    "        \n",
    "    x_t, y_t, x_v, y_v = split_data(X, y)\n",
    "\n",
    "    regr = regression(X, y) \n",
    "    #regr = lasso(x_t, y_t, a = 0.001) \n",
    "    #regr = Bayes(X, y, t = 1e-12) \n",
    "    predicted = regr.predict(x_t)\n",
    "\n",
    "    # Mostrem la predicció del model entrenat en color vermell a la Figura anterior 1\n",
    "    fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "\n",
    "    aux = []\n",
    "    for i,j in zip(x_t,predicted):\n",
    "        aux.append(np.array([i[0],j]))\n",
    "    aux = np.array(aux)\n",
    "    aux = aux[aux[:,0].argsort()]\n",
    "\n",
    "    xi = []\n",
    "    yi = []\n",
    "\n",
    "    for i in aux:\n",
    "        xi.append(np.array([i[0]]))\n",
    "\n",
    "    pred = regr.predict(xi)\n",
    "\n",
    "    xi = []\n",
    "    for i in aux:\n",
    "        xi.append(i[0])\n",
    "        yi.append(i[1])\n",
    "\n",
    "    stdev = np.sqrt(sum((pred - y_t)**2) / (len(y_t) - 2))\n",
    "    min_pred = pred - 0.675*stdev\n",
    "    max_pred = pred + 0.675*stdev\n",
    "\n",
    "    ax.scatter(X, np.array(y), marker='o', color = \"gray\")\n",
    "    ax.plot(xi, np.array(pred), linestyle='-', label=\"OLS\")\n",
    "    ax.plot(xi, np.array(min_pred), linestyle='--', color='red', label=\"95% CI\")\n",
    "    ax.plot(xi, np.array(max_pred), linestyle='--', color='red')\n",
    "    ax.fill_between(xi, np.array(min_pred), np.array(max_pred), alpha=0.1)\n",
    "\n",
    "    media = 0\n",
    "    for pred in predicted:\n",
    "        media += pred\n",
    "    media /= len(predicted)\n",
    "    # Mostrem l'error (MSE i R2)\n",
    "    print(media)\n",
    "    MSE = mse(list(y_v), list(regr.predict(x_v)),0)\n",
    "    r2 = r2_score(y_v, regr.predict(x_v))\n",
    "\n",
    "    print(names_cor)\n",
    "    print(\"Mean squeared error: \", MSE)\n",
    "    print(\"R2 score: \", r2)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    dic[names_cor] = (MSE, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][1] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][1]\n",
    "    if dic[clave][0] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][0]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][1])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CrossValidation ElasNet (Kobe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "def split_data(x, y, train_ratio=0.7):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    n_train = int(np.floor(x.shape[0]*train_ratio))\n",
    "    indices_train = indices[:n_train]\n",
    "    indices_val = indices[n_train:] \n",
    "    x_train = x[indices_train, :]\n",
    "    y_train = y[indices_train]\n",
    "    x_val = x[indices_val, :]\n",
    "    y_val = y[indices_val]\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "\n",
    "names_corr_importants = [\"TS%\", \"USG%\", \"OBPM\", \"BPM\", \"OWS\", \"VORP\"]\n",
    "names_combinations = []\n",
    "for i in range(2,6):\n",
    "    names_combinations+=combinations(names_corr_importants,i)\n",
    "\n",
    "for names_cor in names_combinations:\n",
    "    Dk_copy = data_Kobe_no_estandaritzat.copy()\n",
    "    y = np.array(data_Kobe_no_estandaritzat['PER'])\n",
    "    for i in Dk_copy:\n",
    "        if i not in names_cor:\n",
    "            Dk_copy = Dk_copy.drop(i, axis = 1)\n",
    "\n",
    "    x = Dk_copy.to_numpy()\n",
    "        \n",
    "    x_t, y_t, x_v, y_v = split_data(X, y)\n",
    "\n",
    "    #regr = regression(X, y) \n",
    "    #regr = lasso(x_t, y_t, a = 0.001) \n",
    "    #regr = Bayes(X, y, t = 1e-12) \n",
    "    regr = ElasNet(X,y)\n",
    "    predicted = regr.predict(x_t)\n",
    "\n",
    "    # Mostrem la predicció del model entrenat en color vermell a la Figura anterior 1\n",
    "    fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "\n",
    "    aux = []\n",
    "    for i,j in zip(x_t,predicted):\n",
    "        aux.append(np.array([i[0],j]))\n",
    "    aux = np.array(aux)\n",
    "    aux = aux[aux[:,0].argsort()]\n",
    "\n",
    "    xi = []\n",
    "    yi = []\n",
    "\n",
    "    for i in aux:\n",
    "        xi.append(np.array([i[0]]))\n",
    "\n",
    "    pred = regr.predict(xi)\n",
    "\n",
    "    xi = []\n",
    "    for i in aux:\n",
    "        xi.append(i[0])\n",
    "        yi.append(i[1])\n",
    "\n",
    "    stdev = np.sqrt(sum((pred - y_t)**2) / (len(y_t) - 2))\n",
    "    min_pred = pred - 0.675*stdev\n",
    "    max_pred = pred + 0.675*stdev\n",
    "\n",
    "    ax.scatter(X, np.array(y), marker='o', color = \"gray\")\n",
    "    ax.plot(xi, np.array(pred), linestyle='-', label=\"OLS\")\n",
    "    ax.plot(xi, np.array(min_pred), linestyle='--', color='red', label=\"95% CI\")\n",
    "    ax.plot(xi, np.array(max_pred), linestyle='--', color='red')\n",
    "    ax.fill_between(xi, np.array(min_pred), np.array(max_pred), alpha=0.1)\n",
    "\n",
    "    # Mostrem l'error (MSE i R2)\n",
    "    MSE = mse(list(y_v), list(regr.predict(x_v)),0)\n",
    "    r2 = r2_score(y_v, regr.predict(x_v))\n",
    "\n",
    "    print(names_cor)\n",
    "    print(\"Mean squeared error: \", MSE)\n",
    "    print(\"R2 score: \", r2)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    dic[names_cor] = (MSE, r2, names_cor)\n",
    "    #print(names_cor)\n",
    "    #print(media)\n",
    "    #print(\"Mean squeared error: \", error)\n",
    "    #print(\"R2 score: \", r2)\n",
    "    \n",
    "maxr2 = 0\n",
    "minerror = 100\n",
    "for clave in dic.keys():\n",
    "    if dic[clave][1] > maxr2: #mira la r2 del diccionari\n",
    "        clave_r2 = clave\n",
    "        maxr2 = dic[clave][1]\n",
    "    if dic[clave][0] < minerror: #mira el mse del diccionari\n",
    "        clave_mse = clave\n",
    "        minerror = dic[clave][0]\n",
    "\n",
    "\n",
    "print(\"La combinació amb major r2 és \", clave_r2, \" amb un valor de\", dic[clave_r2][1])\n",
    "print(\"La combinació amb menor mse és \", clave_mse, \" amb un valor de\", dic[clave_mse][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cerca hiperparàmetres Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "dataset_advanced = load_dataset('advanced_stats.csv')\n",
    "utils = []\n",
    "for i in dataset_advanced.columns.values:\n",
    "    if dataset_advanced[i].dtype != \"object\":\n",
    "        utils.append(i)\n",
    "\n",
    "\n",
    "for i in utils:\n",
    "    x = np.array(dataset_advanced[i])\n",
    "    X = x.reshape(x.shape[0], 1) \n",
    "y = np.array(dataset_advanced['PER'])\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "model = Lasso()\n",
    "parameters = {'alpha': uniform(loc=0, scale=10),\n",
    "              'tol'    : uniform(loc=10**(-12), scale=10**(-1)),\n",
    "              'selection' : [\"cyclic\", \"random\"],\n",
    "             }\n",
    "randm_src = RandomizedSearchCV(estimator=model, param_distributions = parameters,\n",
    "                           cv = 2, n_iter = 10, n_jobs=-1)\n",
    "randm_src.fit(X_train, y_train)\n",
    "\n",
    "print(\" Results from Random Search \" )\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", randm_src.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cerca hiperparàmetres BayessianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "dataset_advanced = load_dataset('advanced_stats.csv')\n",
    "utils = []\n",
    "for i in dataset_advanced.columns.values:\n",
    "    if dataset_advanced[i].dtype != \"object\":\n",
    "        utils.append(i)\n",
    "\n",
    "for i in utils:\n",
    "    x = np.array(dataset_advanced[i])\n",
    "    X = x.reshape(x.shape[0], 1) \n",
    "y = np.array(dataset_advanced['PER'])\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "model = BayesianRidge()\n",
    "iters = []\n",
    "for i in range(0,500,25):\n",
    "    iters.append(i)\n",
    "parameters = {'n_iter': iters,\n",
    "              'tol'    : uniform(loc=10**(-12), scale=10**(-1)),\n",
    "              'alpha_1': uniform(loc=10**(-12), scale=10**(-1)),\n",
    "              'alpha_2': uniform(loc=10**(-12), scale=10**(-1)),\n",
    "              'lambda_1': uniform(loc=10**(-12), scale=10**(-1)),\n",
    "              'lambda_2': uniform(loc=10**(-12), scale=10**(-1))\n",
    "             }\n",
    "randm_src = RandomizedSearchCV(estimator=model, param_distributions = parameters,\n",
    "                           cv = 2, n_iter = 10, n_jobs=-1)\n",
    "randm_src.fit(X_train, y_train)\n",
    "\n",
    "print(\" Results from Random Search \" )\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", randm_src.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
